{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:37.318599Z",
     "start_time": "2018-04-27T04:05:37.312584Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing global variables... Done\n",
      "  Filepath set to Tian's directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Filepaths\n",
    "dict_path = \"./Tian/dictionaries/\"\n",
    "model_path = \"./Tian/models/\"\n",
    "hist_path = \"./Tian/histories/\"\n",
    "fig_path = \"./Tian/figs/\"\n",
    "print (\"Done\")\n",
    "print (\"  Filepath set to Tian's directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:37.938403Z",
     "start_time": "2018-04-27T04:05:37.700073Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooking notebook finder... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Hooking notebook finder...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Loader\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        # print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "# Finder\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:39.498391Z",
     "start_time": "2018-04-27T04:05:38.046636Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing custom modules... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Importing custom modules...\", end=' ')\n",
    "import modules\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:39.758093Z",
     "start_time": "2018-04-27T04:05:39.510425Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from disk... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./Tian/Metal_all_20180116.snappy.parquet')\n",
    "# print ('***** Data Types *****' + '\\n' + str(df.dtypes) + '\\n\\n' + \n",
    "#        '***** Unique Ligands *****' + '\\n' + str(df.ligandId.unique()))\n",
    "\n",
    "# Extract zinc-binded, single-chained protein sequences\n",
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "target = np.array(df_zn_single.fingerprint)\n",
    "\n",
    "del df,df_zn,df_zn_single\n",
    "\n",
    "# Remove seqs containing 'U' and 'X'\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] or 'U' in seqs[i]:\n",
    "#         print('Removing...' + str(i))\n",
    "        rows_to_delete.append(i)        \n",
    "        \n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "print (\"Done\")\n",
    "# print (\"Sequence length is \" + str(seqs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:39.780140Z",
     "start_time": "2018-04-27T04:05:39.771118Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross validation split... Done\n",
      "  Ratio : 0.9\n",
      "  Train_range : 0 - 20504\n",
      "  Val_range : 20505 - 22783\n"
     ]
    }
   ],
   "source": [
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:40.245513Z",
     "start_time": "2018-04-27T04:05:39.799192Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading dictionaries...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# ProtVec\n",
    "seqs_dict_w2v = {}\n",
    "with open(dict_path + \"seq_n_gram_to_vec_dict_w_UX\", 'r') as fp:\n",
    "        seqs_dict_w2v = json.load(fp)\n",
    "\n",
    "# One-hot\n",
    "seqs_dict_onehot = {}\n",
    "with open(dict_path + \"seqs_dict_onehot\", 'r') as fp:\n",
    "        seqs_dict_onehot = json.load(fp)\n",
    "\n",
    "# property\n",
    "# blosum62\n",
    "from proteinSequenceEncoder import property_encoder, blosum62_encoder \n",
    "AMINO_ACIDS21 = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \\\n",
    "                 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "seqs_property = {}\n",
    "seqs_blosum62 = {}\n",
    "\n",
    "for aa in AMINO_ACIDS21:\n",
    "    if aa != 'R':\n",
    "        seqs_property[aa] = property_encoder(aa)\n",
    "    seqs_blosum62[aa] = blosum62_encoder(aa)\n",
    "\n",
    "# No R in property encoder\n",
    "seqs_property['R'] = [0] * 7\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- <font color=blue>One-hot Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_onehot}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_onehot}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>ProtVec Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_w2v}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_w2v}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 100),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.ProtVecGenerator(**train_args, **common_args)\n",
    "val_gen = modules.ProtVecGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Property Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_property}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_property}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 7),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Blosum62 Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:42.048341Z",
     "start_time": "2018-04-27T04:05:42.041322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_blosum62}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_blosum62}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- <font color=blue>Single BRNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:43.292590Z",
     "start_time": "2018-04-27T04:05:43.288580Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ProtVec:100, One-hot:20, blosum62:20, property:7\n",
    "dimension = 20\n",
    "cutoff = 706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:45.051315Z",
     "start_time": "2018-04-27T04:05:44.552081Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense,Dropout, TimeDistributed, Bidirectional, Input, Concatenate, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "input_shape = (cutoff, dimension)\n",
    "lstm_size = 64\n",
    "\n",
    "input_0 = Input(shape=input_shape)\n",
    "bd_lstm_0 = Bidirectional(LSTM(lstm_size, return_sequences=True), \n",
    "                          input_shape=input_shape, \n",
    "                          merge_mode='ave')(input_0)      \n",
    "do_0 = Dropout(0.2)(bd_lstm_0)\n",
    "output_0 = TimeDistributed(Dense(1, activation='tanh'))(do_0)\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model = Model(inputs=input_0, outputs=output_0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Threshold: mean+2.33*std</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:46.235767Z",
     "start_time": "2018-04-27T04:05:46.229749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_func(y_in):\n",
    "    factor = 2.33\n",
    "    y_out = np.zeros_like(y_in)\n",
    "    for i in range(y_in.shape[0]):\n",
    "        th= np.mean(y_in[i]) + factor * np.std(y_in[i])\n",
    "        y_out[i] = (y_in[i] > th)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Metric: F1 score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T04:05:47.487468Z",
     "start_time": "2018-04-27T04:05:47.482454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback initialized.\n",
      "Assigning validation generator... Done\n",
      "Matching input shape... Done\n",
      "Matching output shape... Done\n",
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "cb = modules.F1_history(threshold_func)\n",
    "\n",
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [cb]}\n",
    "\n",
    "trainer = modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T04:05:45.591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 24/205 [==>...........................] - ETA: 6:07 - loss: 0.0700"
     ]
    }
   ],
   "source": [
    "trainer.start(epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "with open(hist_path + \"your_f1_histroy_file\", 'w') as fp:\n",
    "        json.dump(cb.f1_scores, fp)\n",
    "model.save(model_path + \"your_model_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "history_of_f1s = []\n",
    "for i in range(50):\n",
    "    history_of_f1s.append(np.average(np.array(cb.f1_scores[i*205:(i+1)*205])))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(0)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('F1 score over batch')\n",
    "ax.plot(history_of_f1s)\n",
    "fig.canvas.draw()\n",
    "plt.show()\n",
    "# plt.savefig(fig_path + \"sgbrnn_oh_adam_31.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file= fig_path + 'your_fig.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
