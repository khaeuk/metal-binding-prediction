{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:27:33.158420Z",
     "start_time": "2018-04-27T03:27:33.155413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that OneHotGenerator supports single char to vector translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.162981Z",
     "start_time": "2018-04-27T03:06:49.082705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    'Gererate data for Keras'\n",
    "    def __init__(self, \n",
    "                 sequences, \n",
    "                 labels, \n",
    "                 translator,\n",
    "                 batch_size = 100, \n",
    "                 input_shape=(706,20),\n",
    "                 label_shape=(706,),\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.translator = translator\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.label_shape = label_shape\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Get the number of batches per epoch'\n",
    "        return int(np.floor(len(self.sequences))/self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        sequences_temp = [self.sequences[k] for k in indices]\n",
    "        labels_temp = [self.labels[k] for k in indices]\n",
    "        \n",
    "        X, y = self.generate_data(sequences_temp, labels_temp)\n",
    "        return X, y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices at the end of each epoch'\n",
    "        self.indices = np.arange(len(self.sequences))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def generate_data(self, sequences_temp, labels_temp):\n",
    "        'Populate input and label tensors'\n",
    "        X = np.zeros((self.batch_size, *self.input_shape))\n",
    "        y = np.zeros((self.batch_size, *self.label_shape), dtype=int)\n",
    "        \n",
    "        cutoff = self.input_shape[0]\n",
    "        dim = self.input_shape[1]\n",
    "        # len(seq) < cutoff - zero padding\n",
    "        # len(seq) >= cutoff - truncate to cutoff\n",
    "        \n",
    "        for i, seq in enumerate(sequences_temp):\n",
    "            \n",
    "            length = len(seq)\n",
    "            for j, c in enumerate(seq):\n",
    "                if j < cutoff:\n",
    "                    X[i,j,] = np.array(self.translator[c])\n",
    "\n",
    "            for j, f in enumerate(labels_temp[i]):\n",
    "                if f < cutoff:\n",
    "                    y[i,f,] = 1\n",
    "            \n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.259265Z",
     "start_time": "2018-04-27T03:06:49.169002Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProtVecGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    'Gererate data for Keras'\n",
    "    def __init__(self, \n",
    "                 sequences, \n",
    "                 labels, \n",
    "                 translator,\n",
    "                 batch_size = 100, \n",
    "                 input_shape=(706,20),\n",
    "                 label_shape=(706,),\n",
    "                 shuffle=True, \n",
    "                 n_gram=3):\n",
    "        'Initialization'\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.translator = translator\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.label_shape = label_shape\n",
    "        self.shuffle = shuffle\n",
    "        self.n_gram=n_gram\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Get the number of batches per epoch'\n",
    "        return int(np.floor(len(self.sequences))/self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        sequences_temp = [self.sequences[k] for k in indices]\n",
    "        labels_temp = [self.labels[k] for k in indices]\n",
    "        \n",
    "        X, y = self.generate_data(sequences_temp, labels_temp)\n",
    "        return X, y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices at the end of each epoch'\n",
    "        self.indices = np.arange(len(self.sequences))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def generate_data(self, sequences_temp, labels_temp):\n",
    "        'Populate input and label tensors'\n",
    "        X = np.zeros((self.batch_size, *self.input_shape))\n",
    "        y = np.zeros((self.batch_size, *self.label_shape), dtype=int)\n",
    "        \n",
    "        cutoff = self.input_shape[0]\n",
    "        dim = self.input_shape[1]\n",
    "        # len(seq) < cutoff - zero padding\n",
    "        # len(seq) >= cutoff - truncate to cutoff\n",
    "        \n",
    "        for i, seq in enumerate(sequences_temp):\n",
    "            \n",
    "            length = len(seq)\n",
    "            offset = self.n_gram - 1\n",
    "            for j in range(length-offset):\n",
    "                if j+offset < cutoff:\n",
    "                    word = seq[j:j+self.n_gram]\n",
    "                    if word in self.translator.keys():\n",
    "                        X[i,j,] = np.array(self.translator[word])\n",
    "\n",
    "            for j, f in enumerate(labels_temp[i]):\n",
    "                if f < cutoff:\n",
    "                    y[i,f,] = 1\n",
    "            \n",
    "        return X, y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.288317Z",
     "start_time": "2018-04-27T03:06:49.265257Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorArray(keras.utils.Sequence):\n",
    "    \n",
    "    'Gererate data for Keras'\n",
    "    def __init__(self, generators):\n",
    "        'Initialization'\n",
    "        for gen in generators:\n",
    "            assert gen is not None\n",
    "        self.generators = generators\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Get the number of batches per epoch'\n",
    "        return min([len(gen) for gen in self.generators])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        X = []\n",
    "        Y = None\n",
    "        for gen in self.generators:\n",
    "            x, y = gen[index]\n",
    "            X.append(x)\n",
    "            if Y is None:\n",
    "                Y = y\n",
    "            assert Y == y\n",
    "            \n",
    "        return X, Y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices at the end of each epoch'\n",
    "        for gen in self.generators:\n",
    "            gen.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.329426Z",
     "start_time": "2018-04-27T03:06:49.294333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenericGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    'Gererate data for Keras'\n",
    "    def __init__(self, \n",
    "                 sequences, \n",
    "                 labels, \n",
    "                 translator,\n",
    "                 generate_func,\n",
    "                 batch_size = 100, \n",
    "                 input_shape=(706,20),\n",
    "                 label_shape=(706,),\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.translator = translator\n",
    "        self.generate_func = generate_func\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.label_shape = label_shape\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Get the number of batches per epoch'\n",
    "        return int(np.floor(len(self.sequences))/self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        sequences_temp = [self.sequences[k] for k in indices]\n",
    "        labels_temp = [self.labels[k] for k in indices]\n",
    "        \n",
    "        X, y = self.generate_func(sequences_temp, labels_temp)\n",
    "        return X, y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices at the end of each epoch'\n",
    "        self.indices = np.arange(len(self.sequences))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.341458Z",
     "start_time": "2018-04-27T03:06:49.336449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:49.392594Z",
     "start_time": "2018-04-27T03:06:49.348478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 generators,\n",
    "                 callbacks):\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        assert len(generators) == 2\n",
    "        self.train_gen = generators[0]\n",
    "        self.val_gen = generators[1]\n",
    "        self.callbacks = callbacks\n",
    "        print (\"Assigning validation generator...\",end=' ')\n",
    "        for cb in callbacks:\n",
    "            if cb.validation_generator is None:\n",
    "                cb.validation_generator = self.val_gen\n",
    "        print (\"Done\")\n",
    "        \n",
    "        print (\"Matching input shape...\", end=' ')            \n",
    "        assert self.model.layers[0].input_shape[1:] == self.train_gen.input_shape\n",
    "        print (\"Done\")\n",
    "        \n",
    "        print (\"Matching output shape...\", end=' ')\n",
    "        assert self.model.layers[-1].output_shape[1:] == self.train_gen.label_shape\n",
    "        print (\"Done\")            \n",
    "            \n",
    "        assert self.train_gen.batch_size == self.val_gen.batch_size        \n",
    "        self.batch_size = self.train_gen.batch_size\n",
    "        print (\"Trainer initialized.\")\n",
    "        \n",
    "    def start(self, epoch=1):\n",
    "        assert epoch > 0 and isinstance(epoch, int)\n",
    "        # Assume the model is compiled for now\n",
    "        self.model.fit_generator(epochs=epoch,\n",
    "                                 generator=self.train_gen,\n",
    "#                                  validation_data=self.val_gen,\n",
    "                                 callbacks=self.callbacks,\n",
    "                                 use_multiprocessing=False, \n",
    "                                 workers=4,\n",
    "                                 verbose=1)\n",
    "        self.post_train(epoch)\n",
    "        \n",
    "#     def stop(self, error_string=\"Unspecified\"):\n",
    "#         self.model.stop_training = True\n",
    "#         print (\"Training stopped. Reason:\", error_string)\n",
    "    \n",
    "    def post_train(self, epoch):\n",
    "        print (\"[End of Training]\")\n",
    "        for c in self.callbacks:\n",
    "            c.post_train(epoch=epoch, batch=len(self.train_gen))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:51.118510Z",
     "start_time": "2018-04-27T03:06:49.398611Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T03:06:51.207723Z",
     "start_time": "2018-04-27T03:06:51.125503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F1_history(keras.callbacks.Callback):\n",
    "    def __init__(self, \n",
    "                 threshold_func):\n",
    "        print (\"Callback initialized.\")\n",
    "        self.threshold_func = threshold_func\n",
    "        \n",
    "        self.validation_generator = None\n",
    "        self.validation_steps = 0\n",
    "        \n",
    "        self.f1_scores = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "#         self.epoch_count = 0\n",
    "        self.validation_steps = len(self.validation_generator)\n",
    "        self.f1_scores = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        return\n",
    "    \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "#         self.batch_count = 0\n",
    "#         self.epoch_count += 1\n",
    "        return\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "#         self.batch_count += 1\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        rand_index = np.random.randint(self.validation_steps)\n",
    "        X_val, y_val = self.validation_generator[rand_index]\n",
    "        \n",
    "        pred_val = self.model.predict_on_batch(X_val) \n",
    "        pred_val = self.threshold_func(pred_val).astype(int)\n",
    "        label_val = y_val\n",
    "        \n",
    "        f1_val = f1_score(label_val.ravel(), pred_val.ravel())\n",
    "        precision_val = precision_score(label_val.ravel(), pred_val.ravel())\n",
    "        recall_val = recall_score(label_val.ravel(), pred_val.ravel())\n",
    "        \n",
    "        self.f1_scores.append(round(f1_val,4))\n",
    "        self.precisions.append(round(precision_val,4))\n",
    "        self.recalls.append(round(recall_val,4))\n",
    "#         print (' F1', round(f1_val, 3))\n",
    "        return\n",
    "\n",
    "    def post_train(self, epoch, batch):\n",
    "        F1_over_epoch = []\n",
    "        for i in range(epoch):\n",
    "            F1_over_epoch.append(np.average(self.f1_scores[i*batch:(i+1)*batch]))\n",
    "\n",
    "        fig = plt.figure(0)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title('F1 score over batch')\n",
    "        ax.plot(F1_over_epoch)\n",
    "        fig.canvas.draw()\n",
    "        plt.show()\n",
    "        # plt.savefig(fig_path + \"sgbrnn_oh_adam_31.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
