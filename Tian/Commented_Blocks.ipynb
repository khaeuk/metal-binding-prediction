{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepossessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Buggy) Construct dict from seqs without U,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqs_noUX = np.array(df.sequence)\n",
    "target_noUX = np.array(df.fingerprint)\n",
    "print (target_noUX.shape)\n",
    "\n",
    "# For All sequences in dataset\n",
    "rows_to_delete = []\n",
    "for i in range(seqs_noUX.shape[0]):\n",
    "    if 'X' in seqs_noUX[i] or 'U' in seqs_noUX[i]:\n",
    "        print('Removing...' + str(i))\n",
    "        rows_to_delete.append(i)        \n",
    "        \n",
    "seqs_noUX = np.delete(seqs_noUX, rows_to_delete, 0)\n",
    "target_noUX = np.delete(target_noUX, rows_to_delete)\n",
    "print (\"Sequence length is \" + str(seqs_noUX.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T06:39:24.855841Z",
     "start_time": "2018-03-08T06:39:24.850827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ProtVec\n",
    "n_gram_size = 3\n",
    "dimension = 100\n",
    "\n",
    "# Onehot\n",
    "\n",
    "\n",
    "# Whether to use simple onehot encoding for inputs\n",
    "UseOnehot = True\n",
    "UseReplicate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input - ProtVec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import biovec\n",
    "\n",
    "# A very simple protein sequences to fasta file conversion\n",
    "def convertSeqsToFasta (seqs, filename):\n",
    "    file = open(filename, 'w')\n",
    "    size = seqs.shape[0]\n",
    "    for i,l in zip(range(size),seqs):\n",
    "        file.write('>' + str(i) + '\\n')\n",
    "        file.write(l + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'exclude_U_X.fasta'\n",
    "convertSeqsToFasta(seqs=seqs_noUX, filename=filename)\n",
    "pv = biovec.models.ProtVec(corpus_fname=filename, n=n_gram_size, size=dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def construct_n_gram_to_vector_dict(filename, seqs, pv, n_gram_size):\n",
    "    n_gram_to_vec = {}\n",
    "    \n",
    "    for i in range(seqs.shape[0]):\n",
    "        for j in range(len(seqs[i])-(n_gram_size-1)):\n",
    "            word = seqs[i][j:j+n_gram_size]\n",
    "            n_gram_to_vec[word] = pv[word].tolist()\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(n_gram_to_vec, fp)  \n",
    "    print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write\n",
    "construct_n_gram_to_vector_dict(dict_path + \"seqs_to_vec_noUX\", seqs, pv, n_gram_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input - Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_keys = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    for j in range(len(seqs[i])):\n",
    "        if seqs[i][j] not in onehot_keys:\n",
    "            onehot_keys.append(seqs[i][j])\n",
    "# import operator\n",
    "# print (sorted(seqs_dict_onehot.items(), key=operator.itemgetter(1)))\n",
    "onehot_keys = np.array(onehot_keys).reshape(-1)\n",
    "np.random.shuffle(onehot_keys)\n",
    "\n",
    "seqs_dict_onehot = {}\n",
    "onehot_matrix = np.eye(onehot_keys.shape[0])\n",
    "for i in range(onehot_keys.shape[0]):\n",
    "    seqs_dict_onehot[onehot_keys[i]] = onehot_matrix[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(dict_path + \"seqs_dict_onehot\", 'w') as fp:\n",
    "    json.dump(seqs_dict_onehot, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T06:37:09.240024Z",
     "start_time": "2018-03-08T06:37:09.236013Z"
    }
   },
   "source": [
    "<img src=\"./figs/length_dist.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UseOnehot:\n",
    "    n_gram_size = 1\n",
    "    dimension = onehot_keys.shape[0]\n",
    "    seqs_dict = seqs_dict_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of sequence lengths\n",
    "lengths = []\n",
    "for item in seqs:\n",
    "    lengths.append(len(item))\n",
    "\n",
    "fig = plt.figure(0)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Sequence Length Distribution')\n",
    "n, bins, rectangles = ax.hist(lengths, 200)\n",
    "fig.canvas.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many to Many BRNN\n",
    "    1. Take average at output states\n",
    "    2. activation function tanh [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many to Many regular RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "# model.add()\n",
    "model.add(LSTM(128, input_shape=(cutoff,dimension)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(cutoff, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input (50,706,100) = 3,530,000 [141200000] \n",
    "#Output (50,706,1) = 35,300 [1412000]\n",
    "\n",
    "history_of_loss = [] # Accumulated loss over epoch * num_of_samples / fold_size\n",
    "histroy_of_roc = []\n",
    "epoch = 5\n",
    "batch_size = 50 # Minibatch size\n",
    "fold_size = 1000 # Input tensor size (fold_size, cutoff, dimension)\n",
    "\n",
    "def training_procedure():\n",
    "    \n",
    "    # Shuffle batch at each epoch\n",
    "    X_train_shuffled, T_train_shuffled = shuffleXY(X_train, T_train)\n",
    "    X_val_shuffled, T_val_shuffled = shuffleXY(X_val, T_val)\n",
    "    \n",
    "    # Construct validation sets\n",
    "    X_Val = construct_X(seqs_dict, X_val_shuffled, cutoff, n_gram_size, dimension, len(X_val_shuffled), 0)\n",
    "    T_Val = np.array(T_val_shuffled).reshape(len(T_val_shuffled), cutoff)\n",
    "    \n",
    "    # 1 to n-1 folds\n",
    "    n = int(len(X_train) / fold_size)\n",
    "    for i in range(n):\n",
    "        print('[' + str(i * fold_size) + '] to [' + str((i+1) * fold_size) + ']')   \n",
    "        X = construct_X(seqs_dict, X_train_shuffled, cutoff, n_gram_size, dimension, fold_size, i * fold_size)\n",
    "        T = np.array(T_train_shuffled[i * fold_size: (i+1) * fold_size]).reshape(fold_size,cutoff)\n",
    "\n",
    "#         hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0)\n",
    "        cb = roc_callback((X,T), (X_Val, T_Val))\n",
    "        hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, \n",
    "                         callbacks=[cb])\n",
    "        \n",
    "        history_of_loss.append(hist.history['loss'])\n",
    "        histroy_of_roc.extend(cb.roc_scores)\n",
    "\n",
    "\n",
    "    # Last fold\n",
    "    last_fold_size = len(X_train) - n * fold_size\n",
    "    print('[' + str(n * fold_size) + '] to [' + str(n * fold_size + last_fold_size) + ']')   \n",
    "\n",
    "    X = construct_X(seqs_dict, X_train_shuffled, cutoff, n_gram_size, dimension, last_fold_size, n * fold_size)\n",
    "    T = np.array(T_train_shuffled[n * fold_size : n * fold_size + last_fold_size]).reshape(last_fold_size,cutoff)\n",
    "\n",
    "    cb = roc_callback((X,T), (X_Val, T_Val))\n",
    "    hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, \n",
    "                         callbacks=[cb])\n",
    "\n",
    "    # hist = model.fit(X, T, epochs=epoch, batch_size=batch_size, verbose=1, \n",
    "    #                     callbacks=[roc_callback((X,T), (X_Val, T_Val))])\n",
    "    history_of_loss.append(hist.history['loss'])\n",
    "    histroy_of_roc.extend(cb.roc_scores)\n",
    "for i in range(epoch):\n",
    "    print ('\\n\\n\\n*** Epoch ', i+1, ' ***')\n",
    "    training_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tried out combinations of onehot/word2vec, replication/zero-padding\n",
    "    1. Onehot + Replication auroc ~ [0.9] 10 epochs\n",
    "<img src=\"./figs/bd_rp_oh_10.png\">\n",
    "    2. W2V + Replication auroc ~ [0.8] (!) 10 epochs\n",
    "<img src=\"./figs/bd_rp_20.png\">\n",
    "    3. Onehot + Zero-padding auroc ~ [0.99] (!) 20 epochs\n",
    "<img src=\"./figs/bd_oh_20.png\">\n",
    "    4. W2V + Zero-padding (Old model) auroc ~ [0.75 - 0.8] 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./figs/hb_lr_10.png\">\n",
    "<img src = \"./figs/hb_lr_20.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Metrics are [ ' + str(history.history.keys()) + ' ]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (np.array(histroy_of_roc)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
