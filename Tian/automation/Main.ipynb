{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:31.258203Z",
     "start_time": "2018-04-20T07:26:31.249182Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing global variables... Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Filepaths\n",
    "dict_path = \"../dictionaries/\"\n",
    "model_path = \"../models/\"\n",
    "hist_path = \"../histories/\"\n",
    "fig_path = \"../figs/\"\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:31.753240Z",
     "start_time": "2018-04-20T07:26:31.506863Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooking notebook finder... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Hooking notebook finder...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Loader\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        # print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "# Finder\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:33.649028Z",
     "start_time": "2018-04-20T07:26:31.948758Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing custom modules... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Importing custom modules...\", end=' ')\n",
    "import Modules\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:34.077415Z",
     "start_time": "2018-04-20T07:26:33.794664Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from disk... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../Metal_all_20180116.snappy.parquet')\n",
    "# print ('***** Data Types *****' + '\\n' + str(df.dtypes) + '\\n\\n' + \n",
    "#        '***** Unique Ligands *****' + '\\n' + str(df.ligandId.unique()))\n",
    "\n",
    "# Extract zinc-binded, single-chained protein sequences\n",
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "target = np.array(df_zn_single.fingerprint)\n",
    "\n",
    "del df,df_zn,df_zn_single\n",
    "\n",
    "# Remove seqs containing 'U' and 'X'\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] or 'U' in seqs[i]:\n",
    "#         print('Removing...' + str(i))\n",
    "        rows_to_delete.append(i)        \n",
    "        \n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "print (\"Done\")\n",
    "# print (\"Sequence length is \" + str(seqs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:34.325074Z",
     "start_time": "2018-04-20T07:26:34.261908Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross validation split... Done\n",
      "  Ratio : 0.9\n",
      "  Train_range : 0 - 20504\n",
      "  Val_range : 20505 - 22783\n"
     ]
    }
   ],
   "source": [
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:35.063047Z",
     "start_time": "2018-04-20T07:26:34.581759Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries... Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading dictionaries...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Load\n",
    "seqs_dict = {}\n",
    "with open(dict_path + \"seq_n_gram_to_vec_dict_w_UX\", 'r') as fp:\n",
    "        seqs_dict = json.load(fp)\n",
    "\n",
    "seqs_dict_onehot = {}\n",
    "with open(dict_path + \"seqs_dict_onehot\", 'r') as fp:\n",
    "        seqs_dict_onehot = json.load(fp)\n",
    "        \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- <font color=blue>One-hot Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:26:52.384258Z",
     "start_time": "2018-04-20T07:26:52.379246Z"
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_onehot}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_onehot}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:27:09.737800Z",
     "start_time": "2018-04-20T07:27:09.733789Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_gen = Modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = Modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:27:27.420862Z",
     "start_time": "2018-04-20T07:27:27.413845Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense,Dropout, TimeDistributed, Bidirectional, Input, Concatenate, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "# Custom layer\n",
    "# from keras import backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "# Utilities\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:27:44.826414Z",
     "start_time": "2018-04-20T07:27:44.824409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (706, 20)\n",
    "lstm_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:28:02.912600Z",
     "start_time": "2018-04-20T07:28:02.379599Z"
    }
   },
   "outputs": [],
   "source": [
    "input_0 = Input(shape=input_shape)\n",
    "bd_lstm_0 = Bidirectional(LSTM(lstm_size, return_sequences=True), \n",
    "                          input_shape=input_shape, \n",
    "                          merge_mode='ave')(input_0)      \n",
    "do_0 = Dropout(0.2)(bd_lstm_0)\n",
    "output_0 = TimeDistributed(Dense(1, activation='tanh'))(do_0)\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model = Model(inputs=input_0, outputs=output_0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:28:02.920339Z",
     "start_time": "2018-04-20T07:28:02.912600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_func(y_in):\n",
    "    factor = 3\n",
    "    y_out = np.zeros_like(y_in)\n",
    "    for i in range(y_in.shape[0]):\n",
    "        th= np.mean(y_in[i]) + factor * np.std(y_in[i])\n",
    "        y_out[i] = (y_in[i] > th)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:28:20.316500Z",
     "start_time": "2018-04-20T07:28:20.312516Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback initialized.\n"
     ]
    }
   ],
   "source": [
    "cb = Modules.F1_history(threshold_func=threshold_func, validation_generator=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:28:55.661431Z",
     "start_time": "2018-04-20T07:28:55.658423Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [cb]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:29:13.328043Z",
     "start_time": "2018-04-20T07:29:13.323029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching input shape... Done\n",
      "Matching output shape... Done\n",
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "trainer = Modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T07:31:28.774431Z",
     "start_time": "2018-04-20T07:29:30.966253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Length of val gen: 22\n",
      "    F1 5.675\n",
      "  1/205 [..............................] - ETA: 16:30 - loss: 0.0406Length of val gen: 22\n",
      "    F1 7.204\n",
      "  2/205 [..............................] - ETA: 11:35 - loss: 0.0435Length of val gen: 22\n",
      "    F1 9.375\n",
      "  3/205 [..............................] - ETA: 10:00 - loss: 0.0434Length of val gen: 22\n",
      "    F1 11.502\n",
      "  4/205 [..............................] - ETA: 9:11 - loss: 0.0415 Length of val gen: 22\n",
      "    F1 10.555\n",
      "  5/205 [..............................] - ETA: 8:38 - loss: 0.0399Length of val gen: 22\n",
      "    F1 12.461\n",
      "  6/205 [..............................] - ETA: 8:18 - loss: 0.0386Length of val gen: 22\n",
      "    F1 14.286\n",
      "  7/205 [>.............................] - ETA: 7:59 - loss: 0.0377Length of val gen: 22\n",
      "    F1 15.244\n",
      "  8/205 [>.............................] - ETA: 7:46 - loss: 0.0369Length of val gen: 22\n",
      "    F1 16.765\n",
      "  9/205 [>.............................] - ETA: 7:35 - loss: 0.0361Length of val gen: 22\n",
      "    F1 20.71\n",
      " 10/205 [>.............................] - ETA: 7:26 - loss: 0.0352Length of val gen: 22\n",
      "    F1 21.295\n",
      " 11/205 [>.............................] - ETA: 7:19 - loss: 0.0344Length of val gen: 22\n",
      "    F1 24.791\n",
      " 12/205 [>.............................] - ETA: 7:13 - loss: 0.0338Length of val gen: 22\n",
      "    F1 22.606\n",
      " 13/205 [>.............................] - ETA: 7:07 - loss: 0.0332Length of val gen: 22\n",
      "    F1 22.816\n",
      " 14/205 [=>............................] - ETA: 7:02 - loss: 0.0326Length of val gen: 22\n",
      "    F1 25.843\n",
      " 15/205 [=>............................] - ETA: 6:57 - loss: 0.0321Length of val gen: 22\n",
      "    F1 22.956\n",
      " 16/205 [=>............................] - ETA: 6:52 - loss: 0.0316Length of val gen: 22\n",
      "    F1 24.687\n",
      " 17/205 [=>............................] - ETA: 6:48 - loss: 0.0312Length of val gen: 22\n",
      "    F1 27.893\n",
      " 18/205 [=>............................] - ETA: 6:44 - loss: 0.0307Length of val gen: 22\n",
      "    F1 28.504\n",
      " 19/205 [=>............................] - ETA: 6:41 - loss: 0.0302Length of val gen: 22\n",
      "    F1 26.109\n",
      " 20/205 [=>............................] - ETA: 6:37 - loss: 0.0298Length of val gen: 22\n",
      "    F1 27.892\n",
      " 21/205 [==>...........................] - ETA: 6:33 - loss: 0.0294Length of val gen: 22\n",
      "    F1 28.068\n",
      " 22/205 [==>...........................] - ETA: 6:30 - loss: 0.0291Length of val gen: 22\n",
      "    F1 28.828\n",
      " 23/205 [==>...........................] - ETA: 6:27 - loss: 0.0289Length of val gen: 22\n",
      "    F1 31.212\n",
      " 24/205 [==>...........................] - ETA: 6:24 - loss: 0.0287Length of val gen: 22\n",
      "    F1 30.89\n",
      " 25/205 [==>...........................] - ETA: 6:21 - loss: 0.0284Length of val gen: 22\n",
      "    F1 31.94\n",
      " 26/205 [==>...........................] - ETA: 6:19 - loss: 0.0281Length of val gen: 22\n",
      "    F1 27.795\n",
      " 27/205 [==>...........................] - ETA: 6:16 - loss: 0.0279Length of val gen: 22\n",
      "    F1 27.375\n",
      " 28/205 [===>..........................] - ETA: 6:13 - loss: 0.0276Length of val gen: 22\n",
      "    F1 30.12\n",
      " 29/205 [===>..........................] - ETA: 6:10 - loss: 0.0274Length of val gen: 22\n",
      "    F1 28.155\n",
      " 30/205 [===>..........................] - ETA: 6:08 - loss: 0.0272Length of val gen: 22\n",
      "    F1 27.455\n",
      " 31/205 [===>..........................] - ETA: 6:06 - loss: 0.0270Length of val gen: 22\n",
      "    F1 26.068\n",
      " 32/205 [===>..........................] - ETA: 6:04 - loss: 0.0268Length of val gen: 22\n",
      "    F1 28.866\n",
      " 33/205 [===>..........................] - ETA: 6:01 - loss: 0.0267Length of val gen: 22\n",
      "    F1 29.217\n",
      " 34/205 [===>..........................] - ETA: 5:59 - loss: 0.0265Length of val gen: 22\n",
      "    F1 28.757\n",
      " 35/205 [====>.........................] - ETA: 5:56 - loss: 0.0263Length of val gen: 22\n",
      "    F1 28.125\n",
      " 36/205 [====>.........................] - ETA: 5:54 - loss: 0.0261Length of val gen: 22\n",
      "    F1 28.339\n",
      " 37/205 [====>.........................] - ETA: 5:51 - loss: 0.0260Length of val gen: 22\n",
      "    F1 29.279\n",
      " 38/205 [====>.........................] - ETA: 5:49 - loss: 0.0258Length of val gen: 22\n",
      "    F1 27.771\n",
      " 39/205 [====>.........................] - ETA: 5:46 - loss: 0.0257Length of val gen: 22\n",
      "    F1 27.555\n",
      " 40/205 [====>.........................] - ETA: 5:44 - loss: 0.0255Length of val gen: 22\n",
      "    F1 29.703\n",
      " 41/205 [=====>........................] - ETA: 5:42 - loss: 0.0254Length of val gen: 22\n",
      "    F1 32.636\n",
      " 42/205 [=====>........................] - ETA: 5:39 - loss: 0.0252Length of val gen: 22\n",
      "    F1 29.211\n",
      " 43/205 [=====>........................] - ETA: 5:37 - loss: 0.0251Length of val gen: 22\n",
      "    F1 28.237\n",
      " 44/205 [=====>........................] - ETA: 5:35 - loss: 0.0250Length of val gen: 22\n",
      "    F1 27.875\n",
      " 45/205 [=====>........................] - ETA: 5:33 - loss: 0.0248Length of val gen: 22\n",
      "    F1 29.134\n",
      " 46/205 [=====>........................] - ETA: 5:30 - loss: 0.0247Length of val gen: 22\n",
      "    F1 29.71\n",
      " 47/205 [=====>........................] - ETA: 5:28 - loss: 0.0246Length of val gen: 22\n",
      "    F1 28.743\n",
      " 48/205 [======>.......................] - ETA: 5:26 - loss: 0.0245Length of val gen: 22\n",
      "    F1 28.757\n",
      " 49/205 [======>.......................] - ETA: 5:24 - loss: 0.0244Length of val gen: 22\n",
      "    F1 30.51\n",
      " 50/205 [======>.......................] - ETA: 5:22 - loss: 0.0243Length of val gen: 22\n",
      "    F1 29.972\n",
      " 51/205 [======>.......................] - ETA: 5:20 - loss: 0.0242Length of val gen: 22\n",
      "    F1 31.655\n",
      " 52/205 [======>.......................] - ETA: 5:18 - loss: 0.0241Length of val gen: 22\n",
      "    F1 29.028\n",
      " 53/205 [======>.......................] - ETA: 5:16 - loss: 0.0240Length of val gen: 22\n",
      "    F1 27.765\n",
      " 54/205 [======>.......................] - ETA: 5:14 - loss: 0.0239Length of val gen: 22\n",
      "    F1 27.858\n",
      " 55/205 [=======>......................] - ETA: 5:12 - loss: 0.0239"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0a9d5ee4159d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Dropbox\\metal-binding-prediction\\Tian\\automation\\Modules.ipynb\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, epoch)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.start(epoch=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "plot_model(model, to_file= fig_path + 'single_brnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "<img src=\"../figs/single_brnn.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
