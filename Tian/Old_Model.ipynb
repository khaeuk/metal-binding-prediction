{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Translating Amino Acid Sequences to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:34.215375Z",
     "start_time": "2018-02-07T20:09:34.211365Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:39.265359Z",
     "start_time": "2018-02-07T20:09:38.970575Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Data Types *****\n",
      "structureChainId      object\n",
      "ligandId              object\n",
      "fingerprint           object\n",
      "groupNumber           object\n",
      "sequence              object\n",
      "interactingChains      int32\n",
      "clusterNumber30      float64\n",
      "clusterNumber40      float64\n",
      "clusterNumber50      float64\n",
      "clusterNumber70      float64\n",
      "clusterNumber90      float64\n",
      "clusterNumber95      float64\n",
      "clusterNumber100     float64\n",
      "dtype: object\n",
      "\n",
      "***** Unique Ligands *****\n",
      "['MN' 'CA' 'MG' 'ZN' 'CU' 'FE' 'CO' 'FE2' 'NI' 'CU1' '3CO' '3NI' 'MN3']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('Metal_all_20180116.snappy.parquet')\n",
    "print ('***** Data Types *****' + '\\n' + str(df.dtypes) + '\\n\\n' + \n",
    "       '***** Unique Ligands *****' + '\\n' + str(df.ligandId.unique()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Use entries with single-chained Zinc-binded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:43.612202Z",
     "start_time": "2018-02-07T20:09:43.579113Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22823,)\n"
     ]
    }
   ],
   "source": [
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "teacher = np.array(df_zn_single.fingerprint)\n",
    "print (seqs.shape)\n",
    "\n",
    "# del df\n",
    "# del df_zn\n",
    "# del df_zn_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### BioVec Embedding using gensim\n",
    "\n",
    "#### https://arxiv.org/pdf/1310.4546.pdf , https://github.com/kyu999/biovec ProtVec module\n",
    "\n",
    "#### Additional ref: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141287 , https://github.com/ehsanasgari/Deep-Proteomics  sample dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:49.374336Z",
     "start_time": "2018-02-07T20:09:49.359288Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import biovec\n",
    "\n",
    "# A very simple protein sequences to fasta file conversion\n",
    "def convertSeqsToFasta (seqs, filename):\n",
    "    file = open(filename, 'w')\n",
    "    size = seqs.shape[0]\n",
    "    for i,l in zip(range(size),seqs):\n",
    "        file.write('>' + str(i) + '\\n')\n",
    "        file.write(l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'all.fasta'\n",
    "convertSeqsToFasta(seqs=df.sequence, filename=filename)\n",
    "pv = biovec.models.ProtVec(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:54.924591Z",
     "start_time": "2018-02-07T20:09:54.497608Z"
    },
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pv = biovec.models.load_protvec('./modelforallwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The output has 3 vectors of dimension 100.\n",
    "# vector_2 -> skipping first letter and make corpus\n",
    "# vecotr_3 -> skipping first and second letters and make corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:09:58.454928Z",
     "start_time": "2018-02-07T20:09:58.432872Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def prepareFeatureVector(inputSeq, teacherSeq, pv):\n",
    "    X = []\n",
    "    T = []\n",
    "    for i in range(teacherSeq.shape[0]):\n",
    "        v = pv.to_vecs(inputSeq[i])\n",
    "        X.extend(v)\n",
    "        T.extend([teacherSeq, teacherSeq, teacherSeq])\n",
    "    return X,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def toVector(seqs, pv):\n",
    "    X1 = {}\n",
    "    X2 = {}\n",
    "    X3 = {}\n",
    "    for i in range(seqs.shape[0]):\n",
    "        G = pv.to_vecs(seqs[i])\n",
    "        X1[i] = G[0].tolist()\n",
    "        X2[i] = G[1].tolist()\n",
    "        X3[i] = G[2].tolist()\n",
    "        \n",
    "    with open('X1', 'w') as fp:\n",
    "        json.dump(X1, fp)\n",
    "    with open('X2', 'w') as fp:\n",
    "        json.dump(X2, fp)\n",
    "    with open('X3', 'w') as fp:\n",
    "        json.dump(X3, fp)\n",
    "    \n",
    "    return X1, X2, X3\n",
    "        \n",
    "X1,X2,X3 = toVector(seqs, pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:10:11.043449Z",
     "start_time": "2018-02-07T20:10:11.040441Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22823\n"
     ]
    }
   ],
   "source": [
    "print (len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:10:07.425794Z",
     "start_time": "2018-02-07T20:10:05.848600Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('X1', 'r') as fp:\n",
    "    X1 = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with open('X2', 'r') as fp:\n",
    "    X2 = json.load(fp)\n",
    "        \n",
    "with open('X3', 'r') as fp:\n",
    "    X3 = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:10:16.749014Z",
     "start_time": "2018-02-07T20:10:16.740993Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def toOnehot(inputSeq, teachingSeq):\n",
    "    T_onehot = []\n",
    "    for i in range(teachingSeq.shape[0]):\n",
    "        t = [0] * len(seqs[i])\n",
    "        for j in teachingSeq[i]:\n",
    "            t[j] = 1 \n",
    "        T_onehot.append(t)        \n",
    "    return T_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:10:19.540658Z",
     "start_time": "2018-02-07T20:10:19.348147Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "T_onehot = toOnehot(inputSeq=X1, teachingSeq=teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## SVM and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:10:25.157127Z",
     "start_time": "2018-02-07T20:10:25.150108Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import LSTM, Input\n",
    "\n",
    "I = Input(shape=(None, 100)) # unknown timespan, fixed feature size\n",
    "lstm = LSTM(20)\n",
    "f = K.function(inputs=[I], outputs=[lstm(I)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# This does work by using only one sample:\n",
    "data = [[0,0,0,0,0,0,0,0,0,2,1]]\n",
    "data = np.array(data, dtype=float)\n",
    "target = [0,0,0,0,0,0,0,0,2,1,0]\n",
    "target = np.array(target, dtype=float)\n",
    "\n",
    "data = data.reshape((1, 1, 11)) # Single batch, 1 time steps, 11 dimentions\n",
    "target = target.reshape((-1, 11)) # Corresponds to shape (None, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:21:25.920087Z",
     "start_time": "2018-02-07T20:21:25.613188Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Sequential()  \n",
    "model.add(LSTM(120, input_shape=(None,100), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:21:28.562114Z",
     "start_time": "2018-02-07T20:21:28.554093Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, None, 120)         106080    \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, None, 1)           121       \n",
      "=================================================================\n",
      "Total params: 106,201\n",
      "Trainable params: 106,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Do the output values match the target values?\n",
    "predict = model.predict(data)\n",
    "print repr(data)\n",
    "print repr(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:21:36.944324Z",
     "start_time": "2018-02-07T20:21:34.640760Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 1.4170 - acc: 0.0089\n",
      "(1, 1, 100) (1, 449, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9114 - acc: 0.0067\n",
      "(1, 1, 100) (1, 449, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8377 - acc: 0.0102\n",
      "(1, 1, 100) (1, 294, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4695 - acc: 0.9924\n",
      "(1, 1, 100) (1, 393, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.9924\n",
      "(1, 1, 100) (1, 393, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.9874\n",
      "(1, 1, 100) (1, 239, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3382 - acc: 0.9718\n",
      "(1, 1, 100) (1, 142, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2836 - acc: 0.9851\n",
      "(1, 1, 100) (1, 202, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1832 - acc: 0.9755\n",
      "(1, 1, 100) (1, 163, 1)\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1811 - acc: 0.9744\n",
      "(1, 1, 100) (1, 156, 1)\n"
     ]
    }
   ],
   "source": [
    "maxIter = 10\n",
    "for i in range(maxIter):\n",
    "    timespan = len(seqs[i])\n",
    "    x = np.array(X1[str(i)]).reshape(1,1,100)\n",
    "    t = np.array(T_onehot[i]).reshape(1,timespan,1)\n",
    "    model.fit(x, t, epochs=1, batch_size=1, verbose=2)\n",
    "    print (x.shape, t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:21:53.829600Z",
     "start_time": "2018-02-07T20:21:53.450597Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "predict = model.predict(np.array(X1[str(0)]).reshape(1,1,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Problems:\n",
    "When doing binary classification site by site\n",
    "1. Variable target length\n",
    "2. Overfitting\n",
    "3. Negative abundance\n",
    "4. Too many similar sequences\n",
    "5. Embedded vectors scale with input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:21:56.272096Z",
     "start_time": "2018-02-07T20:21:56.268088Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.10553339]]]\n"
     ]
    }
   ],
   "source": [
    "print (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class frogNet (keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(frogNet, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "             \n",
    "    def forward(self, inputs, states):\n",
    "          \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, layer_nums):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size) \n",
    "        self.layer_nums = layer_nums\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, layer_nums, batch_first=True).cuda()\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size).cuda()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, features, captions, lengths):\n",
    "        embeddings = self.embed(captions)\n",
    "        inputs = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
    "        inputs_seq = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True)\n",
    "        hiddens, _ = self.lstm(inputs_seq)\n",
    "        outputs = self.linear(hiddens.data)\n",
    "        return outputs\n",
    "    \n",
    "    def forward_real(self, features):\n",
    "        states = None\n",
    "        inputs = features.unsqueeze(1)\n",
    "        res = []\n",
    "        outs = []\n",
    "        for i in range(30):\n",
    "            hidden, states = self.lstm(inputs, states)\n",
    "            outputs = self.linear(hidden.squeeze(1))\n",
    "            outs.append(outputs)\n",
    "            prediction = outputs.max(1)[1]\n",
    "            res.append(prediction)\n",
    "            inputs = self.embed(prediction)\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "        return res, outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Playing with protVec  \n",
    "##### Increase dissimilarity between two sequences by replacing letters of the copy \n",
    "##### Expect to see an increase in standard deviation of difference between two vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_input": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Randomly mutate the copy and check difference in standard deviation\n",
    "seq1 = seq2 = seqs[1]\n",
    "for i in range(10):\n",
    "    target_idx = np.random.randint(len(seq1))\n",
    "    while seq1[target_idx] == seq2[target_idx]:\n",
    "        copy_idx = np.random.randint(len(seq1))\n",
    "        s = list(seq1)\n",
    "        s[target_idx] = seq2[copy_idx]\n",
    "        seq1 = \"\".join(s)\n",
    "    print(np.std(np.array(pv.to_vecs(seq1)) - np.array(pv.to_vecs(seq2))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Test missing corpus duplicates in corpus.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "filename = 'testMissingDuplicates_0.fasta'\n",
    "convertSeqsToFasta(seqs=seqs[:2], filename=filename)\n",
    "pv_0 = biovec.models.ProtVec(filename)\n",
    "pv_0[\"NPQ\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "idx = seqs[0].find(\"NPQ\")\n",
    "s = list(seqs[0])\n",
    "s[idx] = s[idx+1] = s[idx+2] = 'T'\n",
    "seqs[0] = \"\".join(s)\n",
    "filename = 'testMissingDuplicates_1.fasta'\n",
    "convertSeqsToFasta(seqs=seqs[:2], filename=filename)\n",
    "pv_1 = biovec.models.ProtVec(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "298px",
    "left": "1617px",
    "right": "20px",
    "top": "254px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
