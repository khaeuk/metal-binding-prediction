{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OneHot + ProtVec BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:09:54.279775Z",
     "start_time": "2018-03-05T03:09:53.780586Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('Metal_all_20180116.snappy.parquet')\n",
    "# print ('***** Data Types *****' + '\\n' + str(df.dtypes) + '\\n\\n' + \n",
    "#        '***** Unique Ligands *****' + '\\n' + str(df.ligandId.unique()))\n",
    "\n",
    "# Extract zinc-binded, single-chained protein sequences\n",
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "target = np.array(df_zn_single.fingerprint)\n",
    "\n",
    "del df,df_zn,df_zn_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:09:54.860504Z",
     "start_time": "2018-03-05T03:09:54.830423Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length is 22784\n"
     ]
    }
   ],
   "source": [
    "# Remove seqs containing 'U' and 'X'\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] or 'U' in seqs[i]:\n",
    "#         print('Removing...' + str(i))\n",
    "        rows_to_delete.append(i)        \n",
    "        \n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "print (\"Sequence length is \" + str(seqs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol Dict:  {'D': 9266, 'S': 185, 'H': 29210, 'C': 37542, 'E': 4625, 'K': 831, 'G': 47, 'Y': 75, 'N': 217, 'Q': 48, 'A': 31, 'W': 44, 'T': 147, 'R': 32, 'M': 21, 'F': 14, 'I': 18, 'V': 11, 'L': 24, 'P': 2}\n",
      "Total:  82390\n",
      "[C,H / Total]:  0.8101954120645709\n"
     ]
    }
   ],
   "source": [
    "symbol_counts = {}\n",
    "for i in range(seqs.shape[0]):\n",
    "    for j in range(target[i].shape[0]):\n",
    "        if seqs[i][target[i][j]] not in symbol_counts.keys():\n",
    "            symbol_counts[seqs[i][target[i][j]]] = 1\n",
    "        else:\n",
    "            symbol_counts[seqs[i][target[i][j]]] += 1\n",
    "\n",
    "print ('Symbol Dict: ', symbol_counts)\n",
    "print ('Total: ', sum(symbol_counts.values()))\n",
    "print ('[C,H / Total]: ', (symbol_counts['C'] + symbol_counts['H']) / sum(symbol_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Proportion of C,H binding sites \n",
    "\n",
    "All seqs: 0.37\n",
    "\n",
    "Zn-binded, single-chain: 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:09:56.781869Z",
     "start_time": "2018-03-05T03:09:56.773848Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "dict_path = \"./dictionaries/\"\n",
    "model_path = \"./models/\"\n",
    "hist_path = \"./histories/\"\n",
    "fig_path = \"./figs/\"\n",
    "\n",
    "# ProtVec\n",
    "n_gram_size = 3\n",
    "dimension = 100\n",
    "\n",
    "# Onehot\n",
    "\n",
    "\n",
    "# Whether to use simple onehot encoding for inputs\n",
    "UseOnehot = True\n",
    "UseReplicate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Input - ProtVec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:09:58.550833Z",
     "start_time": "2018-03-05T03:09:57.950341Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "seqs_dict = {}\n",
    "with open(dict_path + \"seq_n_gram_to_vec_dict_w_UX\", 'r') as fp:\n",
    "        seqs_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input - Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:10:08.448068Z",
     "start_time": "2018-03-05T03:10:06.594175Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "onehot_keys = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    for j in range(len(seqs[i])):\n",
    "        if seqs[i][j] not in onehot_keys:\n",
    "            onehot_keys.append(seqs[i][j])\n",
    "# import operator\n",
    "# print (sorted(seqs_dict_onehot.items(), key=operator.itemgetter(1)))\n",
    "onehot_keys = np.array(onehot_keys).reshape(-1)\n",
    "np.random.shuffle(onehot_keys)\n",
    "\n",
    "seqs_dict_onehot = {}\n",
    "onehot_matrix = np.eye(onehot_keys.shape[0])\n",
    "for i in range(onehot_keys.shape[0]):\n",
    "    seqs_dict_onehot[onehot_keys[i]] = onehot_matrix[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:10:16.883219Z",
     "start_time": "2018-03-05T03:10:16.873193Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "seqs_dict_onehot = {}\n",
    "with open(dict_path + \"seqs_dict_onehot\", 'r') as fp:\n",
    "        seqs_dict_onehot = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:10:24.841371Z",
     "start_time": "2018-03-05T03:10:24.838362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqs_dicts = [seqs_dict_onehot, seqs_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "if UseOnehot:\n",
    "    n_gram_size = 1\n",
    "    dimension = onehot_keys.shape[0]\n",
    "    seqs_dict = seqs_dict_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Construct feature vector\n",
    "<img src=\"./figs/length_dist.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:10:40.164475Z",
     "start_time": "2018-03-05T03:10:40.073074Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Onehot encoding given a cutoff (Padded with 0s / Replicate partial sequence at the end)\n",
    "def to_onehot(target_single, cutoff, seq_size, replicate=False):\n",
    "    t = [0] * cutoff\n",
    "    offset = cutoff - seq_size\n",
    "    for i in target_single:\n",
    "        t[i] = 1 \n",
    "        if replicate and (i >= seq_size-offset) and (i < seq_size):\n",
    "            t[offset+i] = 1\n",
    "    return t\n",
    "\n",
    "# Convert n-gram to vector given a dictionary\n",
    "def to_vector(seqs_dict, seq, index, n_gram_size, dimension):\n",
    "    if (index+n_gram_size) < len(seq):\n",
    "        word = seq[index: index+n_gram_size]\n",
    "        if '0' not in word:\n",
    "            if word in seqs_dict.keys():\n",
    "                return seqs_dict[word]\n",
    "    return [0] * dimension\n",
    "\n",
    "# Discard sequences longer than the cutoff and reconstruct datasets\n",
    "def optimal_cutoff(seqs, target, cutoff, replicate=False):\n",
    "    new_seqs = []\n",
    "    new_target = []\n",
    "    new_lengths = []\n",
    "    for i, s, t in zip(range(seqs.shape[0]), seqs, target):\n",
    "        if len(s) <= cutoff:\n",
    "            if replicate:\n",
    "                offset = cutoff-len(s)\n",
    "                s = s + s[len(s)-offset : len(s)]\n",
    "                new_seqs.append(s)\n",
    "            else:\n",
    "                new_seqs.append(s + (cutoff-len(s)) * '0')\n",
    "            new_target.append(to_onehot(t,cutoff,len(s), replicate))\n",
    "            new_lengths.append(len(s))\n",
    "    return new_seqs, new_target, new_lengths\n",
    "\n",
    "# Construct input tensor (Num_Samples x Cutoff X Dimension)\n",
    "def construct_X(seqs_dict, seqs, cutoff, n_gram_size, dimension, sample_size, start_index):\n",
    "    X = np.zeros((sample_size, cutoff, dimension))\n",
    "    for i in range(sample_size):\n",
    "        for j in range(cutoff):\n",
    "            X[i][j] = np.array(to_vector(seqs_dict, seqs[start_index + i], j, n_gram_size, dimension))\n",
    "    return X\n",
    "\n",
    "# Get a pair of inputs for testing\n",
    "def randomSample(X, Y):\n",
    "    size = X.shape[0]\n",
    "#     print (X.shape)\n",
    "#     print (Y.shape)\n",
    "    r = np.random.randint(size)\n",
    "    retX = X[r].reshape((1, X.shape[1], X.shape[2]))\n",
    "    retY = Y[r].reshape((1, Y.shape[1]))\n",
    "    return (retX, retY)\n",
    "\n",
    "# Paired randomization \n",
    "def shuffleXY(X, Y):\n",
    "    C = list(zip(X, Y))\n",
    "    random.shuffle(C)\n",
    "    X_ret, Y_ret = zip(*C)\n",
    "    return X_ret, Y_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:10:54.228285Z",
     "start_time": "2018-03-05T03:10:54.037632Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff is 706\n",
      "Training set size is 19577\n",
      "Test set size is 2176\n"
     ]
    }
   ],
   "source": [
    "lengths = np.zeros(len(seqs))\n",
    "for i in range(len(seqs)):\n",
    "    lengths[i] = len(seqs[i])\n",
    "\n",
    "cutoff = int(np.mean(lengths) + 2 * np.std(lengths))\n",
    "print ('Cutoff is ' + str(cutoff))\n",
    "cv_ratio = 0.9\n",
    "\n",
    "X, T, L = optimal_cutoff(seqs, target, cutoff, UseReplicate)\n",
    "X_train, X_val = X[:(int)(len(X) * cv_ratio)], X[(int)(len(X) * cv_ratio):]\n",
    "T_train, T_val = T[:(int)(len(T) * cv_ratio)], T[(int)(len(T) * cv_ratio):]\n",
    "print ('Training set size is ' + str(len(X_train)))\n",
    "print ('Test set size is ' + str(len(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:11:29.406525Z",
     "start_time": "2018-03-05T03:11:28.197314Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense,Dropout, TimeDistributed, Bidirectional, Input, Concatenate, Flatten\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, load_model\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "# Custom layer\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:12:05.117090Z",
     "start_time": "2018-03-05T03:12:03.751711Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def random_sample_n_times(X, Y, size):\n",
    "    X1, X2 = X\n",
    "    n = X1.shape[0]\n",
    "    _X1, _X2, _Y = [], [], []\n",
    "    for i in range(size):\n",
    "        r = np.random.randint(n)\n",
    "        _X1.append(X1[r].tolist())\n",
    "        _X2.append(X2[r].tolist())\n",
    "        _Y.append(Y[r].tolist())\n",
    "        \n",
    "    _X = [np.asarray(_X1), np.asarray(_X2)]\n",
    "    _Y = np.asarray(_Y)\n",
    "    \n",
    "    return _X, _Y\n",
    "    \n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data, sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        \n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        \n",
    "        self.roc_scores = []\n",
    "        self.f1_scores = []\n",
    "        self.precision_scores = []\n",
    "        self.recall_scores = []\n",
    "        \n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.roc_scores = []\n",
    "        self.f1_scores = []\n",
    "        self.precision_scores = []\n",
    "        self.recall_scores = []\n",
    "        return\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = random_sample_n_times(self.x, self.y, self.sample_size)\n",
    "        x_val, y_val = random_sample_n_times(self.x_val, self.y_val, self.sample_size)\n",
    "\n",
    "        y_pred = self.model.predict(x)\n",
    "        y_pred_val = self.model.predict(x_val)\n",
    "\n",
    "        roc = roc_auc_score(y.ravel(), y_pred.ravel())\n",
    "        roc_val = roc_auc_score(y_val.ravel(), y_pred_val.ravel())\n",
    "\n",
    "        \n",
    "        y_pred = (y_pred > 0).astype(int)\n",
    "        y_pred_val = (y_pred_val > 0).astype(int)\n",
    "        \n",
    "        f1 = f1_score(y.ravel(), y_pred.ravel())\n",
    "        precision = precision_score(y.ravel(), y_pred.ravel())\n",
    "        recall = recall_score(y.ravel(), y_pred.ravel())\n",
    "        \n",
    "        f1_val = f1_score(y_val.ravel(), y_pred_val.ravel())\n",
    "        precision_val = precision_score(y_val.ravel(), y_pred_val.ravel())\n",
    "        recall_val = recall_score(y_val.ravel(), y_pred_val.ravel())\n",
    "        \n",
    "#         print (roc_val, f1_val, precision_val, recall_val)\n",
    "        self.roc_scores.append((round(roc,4), round(roc_val,4)))\n",
    "        self.f1_scores.append((round(f1,4), round(f1_val,4)))\n",
    "        self.precision_scores.append((round(precision,4), round(precision_val,4)))\n",
    "        self.recall_scores.append((round(recall,4), round(recall_val,4)))\n",
    "        \n",
    "        return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Model\n",
    "<img src=\"./figs/model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:12:38.891944Z",
     "start_time": "2018-03-05T03:12:38.888898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = [20, 100]\n",
    "lstm_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:13:12.629850Z",
     "start_time": "2018-03-05T03:13:12.611803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class aligned_dense_layer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(aligned_dense_layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create trainable weight variables for this layer.\n",
    "        self.kernel_1 = self.add_weight(name='kernel_1', \n",
    "                                      shape=(input_shape[0][1], 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.kernel_2 = self.add_weight(name='kernel_2', \n",
    "                                      shape=(input_shape[1][1], 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        \n",
    "        self.kernel_offset = self.add_weight(name='kernel_offset', \n",
    "                                      shape=(input_shape[0][1], 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        \n",
    "        super(aligned_dense_layer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.tanh((x[0] * self.kernel_1 + x[1] * self.kernel_2 + self.kernel_offset))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T03:13:47.139357Z",
     "start_time": "2018-03-05T03:13:46.054980Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 706, 20)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 706, 100)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 706, 64)      43520       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 706, 64)      84480       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 706, 64)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 706, 64)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 706, 1)       65          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 706, 1)       65          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aligned_dense_layer_1 (aligned_ (None, 706, 1)       2118        time_distributed_1[0][0]         \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 130,248\n",
      "Trainable params: 130,248\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = [Input(shape=(cutoff, dimensions[0])), \n",
    "          Input(shape=(cutoff, dimensions[1]))]\n",
    "towers = [Bidirectional(LSTM(lstm_size, return_sequences=True), \n",
    "                        input_shape=(cutoff,dimension), \n",
    "                        merge_mode='ave')(inputs[0]),\n",
    "          Bidirectional(LSTM(lstm_size, return_sequences=True), \n",
    "                        input_shape=(cutoff,dimension), \n",
    "                        merge_mode='ave')(inputs[1])]\n",
    "\n",
    "towers = [Dropout(0.2)(towers[0]),\n",
    "          Dropout(0.2)(towers[1])]\n",
    "\n",
    "towers = [TimeDistributed(Dense(1, activation='tanh'))(towers[0]), \n",
    "          TimeDistributed(Dense(1, activation='tanh'))(towers[1])]\n",
    "\n",
    "# towers = [Flatten()(towers[0]), \n",
    "#           Flatten()(towers[1])]\n",
    "\n",
    "\n",
    "output = aligned_dense_layer()([towers[0], towers[1]])\n",
    "# output = Flatten()(output)\n",
    "# output = Dense(1, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file= fig_path + 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T04:37:14.189771Z",
     "start_time": "2018-03-05T03:14:21.278181Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Epoch  1  ***\n",
      "[0] to [500]\n",
      "[500] to [1000]\n",
      "[1000] to [1500]\n",
      "[1500] to [2000]\n",
      "[2000] to [2500]\n",
      "[2500] to [3000]\n",
      "[3000] to [3500]\n",
      "[3500] to [4000]\n",
      "[4000] to [4500]\n",
      "[4500] to [5000]\n",
      "[5000] to [5500]\n",
      "[5500] to [6000]\n",
      "[6000] to [6500]\n",
      "[6500] to [7000]\n",
      "[7000] to [7500]\n",
      "[7500] to [8000]\n",
      "[8000] to [8500]\n",
      "[8500] to [9000]\n",
      "[9000] to [9500]\n",
      "[9500] to [10000]\n",
      "[10000] to [10500]\n",
      "[10500] to [11000]\n",
      "[11000] to [11500]\n",
      "[11500] to [12000]\n",
      "[12000] to [12500]\n",
      "[12500] to [13000]\n",
      "[13000] to [13500]\n",
      "[13500] to [14000]\n",
      "[14000] to [14500]\n",
      "[14500] to [15000]\n",
      "[15000] to [15500]\n",
      "[15500] to [16000]\n",
      "[16000] to [16500]\n",
      "[16500] to [17000]\n",
      "[17000] to [17500]\n",
      "[17500] to [18000]\n",
      "[18000] to [18500]\n",
      "[18500] to [19000]\n",
      "[19000] to [19500]\n",
      "[19500] to [19577]\n",
      "\n",
      "\n",
      "*** Epoch  2  ***\n",
      "[0] to [500]\n",
      "[500] to [1000]\n",
      "[1000] to [1500]\n",
      "[1500] to [2000]\n",
      "[2000] to [2500]\n",
      "[2500] to [3000]\n",
      "[3000] to [3500]\n",
      "[3500] to [4000]\n",
      "[4000] to [4500]\n",
      "[4500] to [5000]\n",
      "[5000] to [5500]\n",
      "[5500] to [6000]\n",
      "[6000] to [6500]\n",
      "[6500] to [7000]\n",
      "[7000] to [7500]\n",
      "[7500] to [8000]\n",
      "[8000] to [8500]\n",
      "[8500] to [9000]\n",
      "[9000] to [9500]\n",
      "[9500] to [10000]\n",
      "[10000] to [10500]\n",
      "[10500] to [11000]\n",
      "[11000] to [11500]\n",
      "[11500] to [12000]\n",
      "[12000] to [12500]\n",
      "[12500] to [13000]\n",
      "[13000] to [13500]\n",
      "[13500] to [14000]\n",
      "[14000] to [14500]\n",
      "[14500] to [15000]\n",
      "[15000] to [15500]\n",
      "[15500] to [16000]\n",
      "[16000] to [16500]\n",
      "[16500] to [17000]\n",
      "[17000] to [17500]\n",
      "[17500] to [18000]\n",
      "[18000] to [18500]\n",
      "[18500] to [19000]\n",
      "[19000] to [19500]\n",
      "[19500] to [19577]\n",
      "\n",
      "\n",
      "*** Epoch  3  ***\n",
      "[0] to [500]\n",
      "[500] to [1000]\n",
      "[1000] to [1500]\n",
      "[1500] to [2000]\n",
      "[2000] to [2500]\n",
      "[2500] to [3000]\n",
      "[3000] to [3500]\n",
      "[3500] to [4000]\n",
      "[4000] to [4500]\n",
      "[4500] to [5000]\n",
      "[5000] to [5500]\n",
      "[5500] to [6000]\n",
      "[6000] to [6500]\n",
      "[6500] to [7000]\n",
      "[7000] to [7500]\n",
      "[7500] to [8000]\n",
      "[8000] to [8500]\n",
      "[8500] to [9000]\n",
      "[9000] to [9500]\n",
      "[9500] to [10000]\n",
      "[10000] to [10500]\n",
      "[10500] to [11000]\n",
      "[11000] to [11500]\n",
      "[11500] to [12000]\n",
      "[12000] to [12500]\n",
      "[12500] to [13000]\n",
      "[13000] to [13500]\n",
      "[13500] to [14000]\n",
      "[14000] to [14500]\n",
      "[14500] to [15000]\n",
      "[15000] to [15500]\n",
      "[15500] to [16000]\n",
      "[16000] to [16500]\n",
      "[16500] to [17000]\n",
      "[17000] to [17500]\n",
      "[17500] to [18000]\n",
      "[18000] to [18500]\n",
      "[18500] to [19000]\n",
      "[19000] to [19500]\n",
      "[19500] to [19577]\n",
      "\n",
      "\n",
      "*** Epoch  4  ***\n",
      "[0] to [500]\n",
      "[500] to [1000]\n",
      "[1000] to [1500]\n",
      "[1500] to [2000]\n",
      "[2000] to [2500]\n",
      "[2500] to [3000]\n",
      "[3000] to [3500]\n",
      "[3500] to [4000]\n",
      "[4000] to [4500]\n",
      "[4500] to [5000]\n",
      "[5000] to [5500]\n",
      "[5500] to [6000]\n",
      "[6000] to [6500]\n",
      "[6500] to [7000]\n",
      "[7000] to [7500]\n",
      "[7500] to [8000]\n",
      "[8000] to [8500]\n",
      "[8500] to [9000]\n",
      "[9000] to [9500]\n",
      "[9500] to [10000]\n",
      "[10000] to [10500]\n",
      "[10500] to [11000]\n",
      "[11000] to [11500]\n",
      "[11500] to [12000]\n",
      "[12000] to [12500]\n",
      "[12500] to [13000]\n",
      "[13000] to [13500]\n",
      "[13500] to [14000]\n",
      "[14000] to [14500]\n",
      "[14500] to [15000]\n",
      "[15000] to [15500]\n",
      "[15500] to [16000]\n",
      "[16000] to [16500]\n",
      "[16500] to [17000]\n",
      "[17000] to [17500]\n",
      "[17500] to [18000]\n",
      "[18000] to [18500]\n",
      "[18500] to [19000]\n",
      "[19000] to [19500]\n",
      "[19500] to [19577]\n",
      "\n",
      "\n",
      "*** Epoch  5  ***\n",
      "[0] to [500]\n",
      "[500] to [1000]\n",
      "[1000] to [1500]\n",
      "[1500] to [2000]\n",
      "[2000] to [2500]\n",
      "[2500] to [3000]\n",
      "[3000] to [3500]\n",
      "[3500] to [4000]\n",
      "[4000] to [4500]\n",
      "[4500] to [5000]\n",
      "[5000] to [5500]\n",
      "[5500] to [6000]\n",
      "[6000] to [6500]\n",
      "[6500] to [7000]\n",
      "[7000] to [7500]\n",
      "[7500] to [8000]\n",
      "[8000] to [8500]\n",
      "[8500] to [9000]\n",
      "[9000] to [9500]\n",
      "[9500] to [10000]\n",
      "[10000] to [10500]\n",
      "[10500] to [11000]\n",
      "[11000] to [11500]\n",
      "[11500] to [12000]\n",
      "[12000] to [12500]\n",
      "[12500] to [13000]\n",
      "[13000] to [13500]\n",
      "[13500] to [14000]\n",
      "[14000] to [14500]\n",
      "[14500] to [15000]\n",
      "[15000] to [15500]\n",
      "[15500] to [16000]\n",
      "[16000] to [16500]\n",
      "[16500] to [17000]\n",
      "[17000] to [17500]\n",
      "[17500] to [18000]\n",
      "[18000] to [18500]\n",
      "[18500] to [19000]\n",
      "[19000] to [19500]\n",
      "[19500] to [19577]\n"
     ]
    }
   ],
   "source": [
    "history_of_loss = [] # Accumulated loss over epoch * num_of_samples / fold_size\n",
    "histroy_of_roc = []\n",
    "history_of_f1 = []\n",
    "history_of_precision = []\n",
    "history_of_recall = []\n",
    "\n",
    "epoch = 5\n",
    "batch_size = 100 # Minibatch size\n",
    "fold_size = 500 # Input tensor size (fold_size, cutoff, dimension)\n",
    "\n",
    "def training_procedure():\n",
    "    \n",
    "    # Shuffle batch at each epoch\n",
    "    X_train_shuffled, T_train_shuffled = shuffleXY(X_train, T_train)\n",
    "    X_val_shuffled, T_val_shuffled = shuffleXY(X_val, T_val)\n",
    "    \n",
    "    # Construct validation sets\n",
    "    X_Vals = [construct_X(seqs_dicts[0], X_val_shuffled, cutoff, n_gram_size, dimensions[0], len(X_val_shuffled), 0),\n",
    "              construct_X(seqs_dicts[1], X_val_shuffled, cutoff, n_gram_size, dimensions[1], len(X_val_shuffled), 0)]\n",
    "    T_Vals = np.array(T_val_shuffled).reshape(len(T_val_shuffled), cutoff,1)\n",
    "    \n",
    "    # 1 to n-1 folds\n",
    "    n = int(len(X_train) / fold_size)\n",
    "    for i in range(n):\n",
    "        print('[' + str(i * fold_size) + '] to [' + str((i+1) * fold_size) + ']')   \n",
    "        X = [construct_X(seqs_dicts[0], X_train_shuffled, cutoff, n_gram_size, dimensions[0], fold_size, i * fold_size),\n",
    "             construct_X(seqs_dicts[1], X_train_shuffled, cutoff, n_gram_size, dimensions[1], fold_size, i * fold_size)]\n",
    "        \n",
    "        T = np.array(T_train_shuffled[i * fold_size: (i+1) * fold_size]).reshape(fold_size,cutoff,1)\n",
    "\n",
    "        cb = roc_callback((X,T), (X_Vals, T_Vals), batch_size)\n",
    "        hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, callbacks=[cb])\n",
    "        \n",
    "        history_of_loss.append(hist.history['loss'])\n",
    "        histroy_of_roc.extend(cb.roc_scores)\n",
    "        history_of_f1.extend(cb.f1_scores)\n",
    "        history_of_precision.extend(cb.precision_scores)\n",
    "        history_of_recall.extend(cb.recall_scores)\n",
    "\n",
    "    # Last fold\n",
    "    last_fold_size = len(X_train) - n * fold_size\n",
    "    print('[' + str(n * fold_size) + '] to [' + str(n * fold_size + last_fold_size) + ']')   \n",
    "\n",
    "    X = [construct_X(seqs_dicts[0], X_train_shuffled, cutoff, n_gram_size, dimensions[0], last_fold_size, n * fold_size),\n",
    "         construct_X(seqs_dicts[1], X_train_shuffled, cutoff, n_gram_size, dimensions[1], last_fold_size, n * fold_size)]\n",
    "    T = np.array(T_train_shuffled[n * fold_size : n * fold_size + last_fold_size]).reshape(last_fold_size,cutoff,1)\n",
    "\n",
    "    cb = roc_callback((X,T), (X_Vals, T_Vals), batch_size)\n",
    "    hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, callbacks=[cb])\n",
    "\n",
    "    history_of_loss.append(hist.history['loss'])\n",
    "    histroy_of_roc.extend(cb.roc_scores)\n",
    "    history_of_f1.extend(cb.f1_scores)\n",
    "    history_of_precision.extend(cb.precision_scores)\n",
    "    history_of_recall.extend(cb.recall_scores)\n",
    "    \n",
    "for i in range(epoch):\n",
    "    print ('\\n\\n*** Epoch ', i+1, ' ***')\n",
    "    training_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Many to Many BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        self.roc_scores = []\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.roc_scores = []\n",
    "        return\n",
    "    def on_train_end(self, logs={}):\n",
    "        return \n",
    "#     def on_epoch_begin(self, epoch, logs={}):\n",
    "#         return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "#         print (self.y.shape, y_pred.shape)\n",
    "        roc = roc_auc_score(self.y.ravel(), y_pred.ravel())\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "#         print (self.y_val.shape, y_pred_val.shape)\n",
    "\n",
    "        roc_val = roc_auc_score(self.y_val.ravel(), y_pred_val.ravel())\n",
    "#         print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        self.roc_scores.append((round(roc,4), round(roc_val,4)))\n",
    "        return \n",
    "\n",
    "#     def on_batch_begin(self, batch, logs={}):\n",
    "#         return\n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "# Build Model\n",
    "bd_model = Sequential()\n",
    "# model.add()\n",
    "bd_model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(cutoff,dimension), merge_mode='ave'))\n",
    "bd_model.add(Dropout(0.2))\n",
    "bd_model.add(TimeDistributed(Dense(1, activation='tanh')))\n",
    "bd_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[])\n",
    "bd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = bd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#Input (50,706,100) = 3,530,000 [141200000] \n",
    "#Output (50,706,1) = 35,300 [1412000]\n",
    "\n",
    "history_of_loss = [] # Accumulated loss over epoch * num_of_samples / fold_size\n",
    "histroy_of_roc = []\n",
    "epoch = 20\n",
    "batch_size = 50 # Minibatch size\n",
    "fold_size = 1000 # Input tensor size (fold_size, cutoff, dimension)\n",
    "\n",
    "def training_procedure():\n",
    "    \n",
    "    # Shuffle batch at each epoch\n",
    "    X_train_shuffled, T_train_shuffled = shuffleXY(X_train, T_train)\n",
    "    X_val_shuffled, T_val_shuffled = shuffleXY(X_val, T_val)\n",
    "    \n",
    "    # Construct validation sets\n",
    "    X_Val = construct_X(seqs_dict, X_val_shuffled, cutoff, n_gram_size, dimension, len(X_val_shuffled), 0)\n",
    "    T_Val = np.array(T_val_shuffled).reshape(len(T_val_shuffled), cutoff,1)\n",
    "    \n",
    "    # 1 to n-1 folds\n",
    "    n = int(len(X_train) / fold_size)\n",
    "    for i in range(n):\n",
    "        print('[' + str(i * fold_size) + '] to [' + str((i+1) * fold_size) + ']')   \n",
    "        X = construct_X(seqs_dict, X_train_shuffled, cutoff, n_gram_size, dimension, fold_size, i * fold_size)\n",
    "        T = np.array(T_train_shuffled[i * fold_size: (i+1) * fold_size]).reshape(fold_size,cutoff,1)\n",
    "\n",
    "#         hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0)\n",
    "        cb = roc_callback((X,T), (X_Val, T_Val))\n",
    "        hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, \n",
    "                         callbacks=[cb])\n",
    "        \n",
    "        history_of_loss.append(hist.history['loss'])\n",
    "        histroy_of_roc.extend(cb.roc_scores)\n",
    "\n",
    "\n",
    "    # Last fold\n",
    "    last_fold_size = len(X_train) - n * fold_size\n",
    "    print('[' + str(n * fold_size) + '] to [' + str(n * fold_size + last_fold_size) + ']')   \n",
    "\n",
    "    X = construct_X(seqs_dict, X_train_shuffled, cutoff, n_gram_size, dimension, last_fold_size, n * fold_size)\n",
    "    T = np.array(T_train_shuffled[n * fold_size : n * fold_size + last_fold_size]).reshape(last_fold_size,cutoff,1)\n",
    "\n",
    "    cb = roc_callback((X,T), (X_Val, T_Val))\n",
    "    hist = model.fit(X, T, epochs=1, batch_size=batch_size, verbose=0, \n",
    "                         callbacks=[cb])\n",
    "\n",
    "    # hist = model.fit(X, T, epochs=epoch, batch_size=batch_size, verbose=1, \n",
    "    #                     callbacks=[roc_callback((X,T), (X_Val, T_Val))])\n",
    "    history_of_loss.append(hist.history['loss'])\n",
    "    histroy_of_roc.extend(cb.roc_scores)\n",
    "for i in range(epoch):\n",
    "    print ('\\n\\n*** Epoch ', i+1, ' ***')\n",
    "    training_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T04:39:23.788106Z",
     "start_time": "2018-03-05T04:39:23.766047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(hist_path + \"hb_5\", 'w') as fp:\n",
    "        json.dump((history_of_loss, histroy_of_roc, history_of_f1, history_of_precision, history_of_recall), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T04:40:04.920317Z",
     "start_time": "2018-03-05T04:40:04.828937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(model_path + \"hb_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(model_path + \"bd_model_oh_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(hist_path + \"bd_history_oh_20\", 'r') as fp:\n",
    "    history_of_loss, histroy_of_roc = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T04:42:48.064523Z",
     "start_time": "2018-03-05T04:42:47.968547Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAABvCAYAAADygIeVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFIxJREFUeJzt3Xt0nVWZx/HvL/frSduklyS9pJUW\nmlTkDurSqYq3LpddzjBQxBuijDDeHR1c6gyDOotxHAVH1yAiclEKiCAdBUEFRBkKtKBIwsXaC01T\nWtrSJr3QNukzf7z7nJ6G5ORNmuTknPN81jqrJ++73/fd+yQ9z9l7v2c/MjOcc865wRRluwLOOecm\nNg8UzjnnMvJA4ZxzLiMPFM455zLyQOGccy4jDxTOOecy8kDhXAGR1C5pcbbr4XKLBwqXFZLWSzoz\n2/UYT5IekPSR8HyxpM4xvt51kr6Wvs3M2szsgbG8rss/HiicGwOSisf4/CVjeX7n0nmgcBOOpI9K\nWiNph6QVkprCdkn6tqStknZJelLSorBviaQOST2SNkn6p0HOXSTpy5I2hPPcIKku7PuVpI/3K/8n\nSX8bnh8n6dehXs9KOjut3HWS/kfSXZL2AG/K0L5q4G6gSdLu8GgKdbtE0l8lbZd0q6Qp4ZgWSSbp\nAknPA/eF7T+V9EJ4PR6U1Ba2XwicB3whnP9/w/ZUT05SuaQrJHWFxxWSysO+xZI6JX0uvE6bJZ2f\n1oZYr7fLE2bmD3+M+wNYD5w5wPY3A9uAk4By4L+BB8O+twOrgUmAgIVAY9i3GXhDeD4ZOGmQ634Y\nWAPMA2qA24Ebw74PAA+llW0FdoZ6VAMbgfOBklC/bUBbKHsdsAt4PdEHsIoBrv0A8JHwfDHQ2W//\np4GVwMxwze8Dy8O+FsCAG0JdKtPaUxvKXwH8Me181wFfG+x1By4L15sGTAX+D/hqWv16Q5lSYAmw\nF5g8nNfbH/nx8B6Fm2jOA641s8fNbD/wReC1klqAg0RviscBMrOnzWxzOO4g0CopYWYvmdnjGc7/\nLTNba2a7w/mXhaGcO4ATJM1JK3t7qMe7gPVm9iMz6w3n/xlwVtq57zSzh8zskJm9PIK2/wPwJTPr\nDNe8FDir3zDTpWa2x8z2AZjZtWbWk1b+NckeUgznAZeZ2VYzexH4N+D9afsPhv0HzewuYDdwbNq+\nOK+3ywMeKNxE0wRsSP4Q3sy3A81mdh/wXeB7wBZJV0tKhKJ/R/Spd4Ok30l6bZzzh+clwHQz6wF+\nCSwL+5YBPwnP5wCnS9qZfBC90c5IO9fGEbX4sDnAHWnnfxroA6YPdA1JxZIuD0NV3US9BYCGmNcb\n6LVoSvt5u5n1pv28l6gXBvFfb5cHPFC4iaaL6A0TSI3n1wObAMzsO2Z2MtAGLAA+H7Y/ZmZLiYZR\nfg7cGuf8wGyiIZYt4eflwLnhja8SuD9s3wj8zswmpT1qzOyitHMNZynmgcpuBN7Z7xoVZrZpkOPe\nCywFzgTqiIanIBqWi1OfgV6LrliVj/96uzzggcJlU6mkirRHCXATcL6kE8LE6r8Dj5jZekmnSjpd\nUimwB3gZ6JNUJuk8SXVmdhDoJvokPpDlwGckzZVUE85/S9on57uI3jwvC9sPhe2/ABZIer+k0vA4\nVdLCEbZ9C1Dfb5joKuDryaEvSVMlLc1wjlpgP1GPqyq0pf815mU4fjnw5XCdBuBfgB8PVfFhvt4u\nD3igcNl0F7Av7XGpmf0W+ArR+P9m4FUcHgpKAD8AXiIaJtkOfDPsez+wPgzBfAx43yDXvBa4EXgQ\nWEcUbD6R3BnG+m8n+pR+U9r2HuBtoS5dwAvAfxBNIg+bmT1D9Ea9Ngw1NQFXAiuAeyX1EE00n57h\nNDcQvQ6bgI5QPt0PieYRdkr6+QDHfw1YBTwJ/Bl4PGyLI+7r7fKAzDxxkXPOucF5j8I551xGHiic\nc85l5IHCOedcRh4onHPOZeSBwjnnXEZ5sQJlQ0ODtbS0ZLsazjmXU1avXr3NzKYOVS4vAkVLSwur\nVq0a9nF7D/RSWVqMpKELO+dcnpG0YehSeRIoRuqzt/yJleu209aUoK2pjtbGBG1NCeZNraG4yIOH\nc85BgQeKd756BpOqSmnv6ua6h9ZzoC9araGitIjjZiRSAaStKcGxM2qpKB3TXDTOOTch5cU3s085\n5RQbydBTuoN9h1izdTftXd20d+2ivaubp7u66dkfLQFUXCSOmVpDW1OC1vBoa6yjrqp0NJrgnHPj\nTtJqMztlyHIeKAZ36JCx8aW9dHR1HxFAtvbsT5WZObnyiJ5HW1Md0xPlPu/hnJvw4gaKgh56GkpR\nkZhTX82c+mre+erG1PYXe/angkZHCCD3tG9J7a+vLjvc6wgBZG59NUU+7+Gcy0EeKEZgam05i4+d\nxuJjp6W29bx8kGde6KF9067Q++jm2j+s42Bf1GOrKitmYWNy3iMKIPOn11Be4vMezrmJzYeextCB\n3kM8t6Un1eto7+rm6c3d7DkQLd1fUiTmT69N3W2VnP+orfB5D+fc2POhpwmgrKSIRc11LGquA2YB\n0bzHhh17U4Gjvaub3z23lZ893pk6bk591eFbdkMAmVZbkaVWOOcKnQeKcVZUJOY2VDO3oZp3HR+l\nJzYztibnPTZFwePPm3Zx159fSB03tbY86nE0Hp73mD2lyuc9nHNjzgPFBCCJ6YkKpicqePNx01Pb\nd+07yNObD99x1dHVze//so2+Q9FwYU15Ca2NiVSvIznvUVrsS3g550aPB4oJrK6ylDPm1XPGvPrU\ntpcP9vHclp4jgsctj21k38Fo3qOsuIj502uOuGV3YWOC6nL/VTvnRsbfPXJMRWkxx8+cxPEzJ6W2\n9R0y1m3bkwoc7V3d/LpjC7euiuY9JJhbX33E7bptTQnqa0aU7tk5V2A8UOSB4iJxzLQajplWw9IT\nmoFo3mPzrpeP+KLgE8/v5BdPbk4dNyNRkTZsFQWRmZMr/cuCzrkjeKDIU5JomlRJ06RK3tp6eN5j\n594Dr/im+QPPbiVMe5CoKOnX86jjVVOrKfF5D+cKlgeKAjOpqozXHdPA645pSG3bd6CPZ16IgkdH\nmDz/8coN7O+NFkksKyniuBm14XseYd5jRoLKMv+yoHOFwAOFo7KsmBNnT+bE2ZNT23r7DrE2zHsk\nb9n95ZObWf7oRgCKBPOm1hwxbNXamGBydVm2muGcGyOxAoWkdwBXAsXANWZ2eb/95cANwMnAduAc\nM1sf9n0RuADoAz5pZveE7ZOAa4BFgAEfNrOHJU0BbgFagPXA2Wb20lG10g1bSXERC6bXsmB6Le85\nMdpmZnS+tC/V8+jo2sWj63Zw5x+7Usc11VWkeh1tTQnamutoqqvweQ/nctiQS3hIKgaeA94KdAKP\nAeeaWUdamYuB483sY5KWAe8xs3MktQLLgdOAJuA3wAIz65N0PfB7M7tGUhlQZWY7JX0D2GFml0u6\nBJhsZv+cqY4TdQmPQrF99/7UkFVy7mPdtj0k/7QmVZX2W2E3wdwGTw7lXLaN5hIepwFrzGxtOPHN\nwFKgI63MUuDS8Pw24LuKPkIuBW42s/3AOklrgNMktQNvBD4EYGYHgANp51ocnl8PPABkDBQuu+pr\nynnD/Km8Yf7h1Lt79vfyzAs9dKQtVeLJoZzLTXECRTOwMe3nTuD0wcqYWa+kXUB92L6y37HNwD7g\nReBHkl4DrAY+ZWZ7gOlmtjmca7OkabicU11ewslzJnPynMPzHgMlh1rxxy5+8sjzwCuTQyXXuqqr\n9EUSncumOIFioPGB/uNVg5UZbHsJcBLwCTN7RNKVwCXAV2LUJ7qgdCFwIcDs2bPjHuayqLS4iIWN\n0TfFzzp5JjBwcqg/rNnG7U9sSh3nyaGcy644gaKT5NKnkZlA1yBlOiWVAHXAjgzHdgKdZvZI2H4b\nUaAA2CKpMfQmGoGtA1XKzK4GroZojiJGO9wEdLTJoZLBo9WTQzk3ZuIEiseA+ZLmApuAZcB7+5VZ\nAXwQeBg4C7jPzEzSCuAmSd8imsyeDzwaJrM3SjrWzJ4F3sLhOY/kuS4P/955VC10OWmg5FC79/dG\niySmJYf64R/WenIo58ZYrMRFkpYAVxDdHnutmX1d0mXAKjNbIakCuBE4kagnsSxt8vtLwIeBXuDT\nZnZ32H4C0e2xZcBa4Hwze0lSPXArMBt4Hvh7M9uRqX5+11PhipscKpUYqtGTQzmXFPeuJ89w5/LO\nQMmhOrp2sW33gVQZTw7lnGe4cwUsbnKopzZ1D5gcKv2b5p4cyjkPFK5AjDQ5VG15CQs9OZQrcB4o\nXEEbaXKoBTNqaGuso605mvfw5FAun/lftnP9xE0OdW/HC9yyKvouqieHcvnMA4VzMcRJDtUxSHKo\n1B1XnhzK5SgPFM6N0HCSQ93vyaFcDvNA4dwoG0lyqPKQHKo17ZvmnhzKTRQeKJwbB/GTQ3Wx/NFo\nkcSBkkO1NSWYVOXJodz48kDhXJZkSg6V7HUMlByqeVIlreFb5p4cyo0HDxTOTSCSmDWlillTqnh7\n24zU9oGSQ/3m6S2p5FCTq0pfcceVJ4dyo8UDhXM5YCTJoSpLizmusTb0PDw5lBs5X+vJuTwyUHKo\np7u66dnfC3hyKHckXxTQOQdE8x4bd+xLWyQx+ndrz/5UmVlTKmlrrDtiqRJPDpX/fFFA5xwQzXvM\nrq9idn3VkMmhftV+eJHE/smh2poStHhyqILkgcK5AjWS5FDVITlU/0USPTlUfvOhJ+dcRv2TQ3Vs\njnogyeRQpcXimGm1R3zfY2FjrSeHygE+9OScGxVlJUUsaq5jUXMdMAsYODnUA89u5bbVnanjPDlU\n/vBA4ZwbtjjJoTo2D50cqq0pwazJnhxqovNA4ZwbFZ4cKn95oHDOjamhkkMl5z4yJYdqa0pw3AxP\nDpUt/qo758bdiJNDNVQf8U1zTw41PjxQOOcmhKGSQyV7HpmTQ0UBxJNDjS4PFM65CcuTQ00MHiic\nczknU3Ko9FV2MyWHSs57eHKooXmgcM7lBU8ONXY8UDjn8tZgyaE27dyX6nVkSg6VHjwaCzg5lAcK\n51xBkcTMyVXMnOzJoeLyQOGccxxdcqjUUiWN+ZkcyhcFdM65Ycin5FCeuMg558bJcJJDtTUlaGtO\n0NqY/eRQo7p6rKR3AFcCxcA1ZnZ5v/3lwA3AycB24BwzWx/2fRG4AOgDPmlm94Tt64GesL03WVlJ\nJwBXARVAL3CxmT0ap57OOZcN+Z4casgehaRi4DngrUAn8Bhwrpl1pJW5GDjezD4maRnwHjM7R1Ir\nsBw4DWgCfgMsMLO+EChOMbNt/a53L/BtM7tb0hLgC2a2OFMdvUfhnMsVAyWH+svWnlckh0pfon2s\nkkONZo/iNGCNma0NJ74ZWAp0pJVZClwant8GfFdRf2opcLOZ7QfWSVoTzvdwhusZkAjP64CuDGWd\ncy6n1JSXcGrLFE5tmZLalp4cKrrzahe3re7k+oc3ANlPDhUnUDQDG9N+7gROH6yMmfVK2gXUh+0r\n+x3bHJ4bcK8kA75vZleH7Z8G7pH0TaAIeF385jjnXO45MjlUJE5yqJb6Kn7wgVOYP712TOsXJ1AM\nNFjWf7xqsDKZjn29mXVJmgb8WtIzZvYgcBHwGTP7maSzgR8CZ76iUtKFwIUAs2fPjtEM55zLHUMl\nh0qudTUtMfZZA+MEik6S+Q8jM3nlcFCyTKekEqIhox2ZjjWz5L9bJd1BNCT1IPBB4FOh/E+Bawaq\nVOiBXA3RHEWMdjjnXE4bLDnUWIuzlOJjwHxJcyWVAcuAFf3KrCB6gwc4C7jPolnyFcAySeWS5gLz\ngUclVUuqBZBUDbwNeCoc3wX8TXj+ZuAvI2uac8650TBkjyLMOXwcuIfo9thrzaxd0mXAKjNbQTQ8\ndGOYrN5BFEwI5W4lmvjuBf4x3PE0Hbgj3D9cAtxkZr8Kl/wocGXombxMGF7KZPXq1dskbRhWyw9r\nALYNWSq/eJsLg7c5/x1te+fEKZQXX7g7GpJWxbk9LJ94mwuDtzn/jVd7PYuHc865jDxQOOecy8gD\nRbhzqsB4mwuDtzn/jUt7C36OwjnnXGbeo3DOOZdRwQQKSe+Q9KykNZIuGWB/uaRbwv5HJLWMfy1H\nV4w2f1ZSh6QnJf1WUqxb5SayodqcVu4sSSYpp++QidNeSWeH33O7pJvGu46jLcbf9WxJ90t6Ivxt\nL8lGPUeTpGslbZX01CD7Jek74TV5UtJJo1oBM8v7B9H3P/4KzAPKgD8Brf3KXAxcFZ4vA27Jdr3H\noc1vAqrC84sKoc2hXC3RKgAriVYwznrdx/B3PB94Apgcfp6W7XqPQ5uvBi4Kz1uB9dmu9yi0+43A\nScBTg+xfAtxNtGzSGcAjo3n9QulRpFbANbMDQHIF3HRLgevD89uAtyi3M6kP2WYzu9/M9oYfVxIt\nsZLL4vyeAb4KfIPoC525LE57Pwp8z8xegmjJnHGu42iL0+a8W4HaonXwdmQoshS4wSIrgUmSGjOU\nH5ZCCRQDrYDbPFgZM+sFkivg5qo4bU53AdEnklw2ZJslnQjMMrNfjGfFxkic3/ECYIGkhyStDEnI\nclmcNl8KvE9SJ3AX8InxqVpWDff/+7DEynCXB45mBdxcFbs9kt4HnMLhNbZyVcY2SyoCvg18aLwq\nNMbi/I5LiIafFhP1GH8vaZGZ7Rzjuo2VOG0+F7jOzP5L0muJlhdaZGaHxr56WTOm71+F0qMYzgq4\n9FsBN1fFaTOSzgS+BLzbogRTuWyoNtcCi4AHQobFM4AVOTyhHffv+k4zO2hm64BniQJHrorT5guA\nWwHM7GGitMoN41K77In1/32kCiVQHM0KuLlqyDaHYZjvEwWJXB+7hiHabGa7zKzBzFrMrIVoXubd\nZpareXTj/F3/nOimBSQ1EA1FrR3XWo6uOG1+HngLgKSFRIHixXGt5fhbAXwg3P10BrDLzDaP1skL\nYujJjmIF3FwVs83/CdQAPw3z9s+b2buzVumjFLPNeSNme+8B3iapA+gDPm9m27NX66MTs82fA34g\n6TNEwy8fyvEPfUhaTjR82BDmXv4VKAUws6uI5mKWAGuAvcD5o3r9HH/9nHPOjbFCGXpyzjk3Qh4o\nnHPOZeSBwjnnXEYeKJxzzmXkgcI551xGHiicc85l5IHCOedcRh4onHPOZfT/YiID1A0thScAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16a8ccfbd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1)\n",
    "ax_loss = fig.add_subplot(311)\n",
    "ax_loss.set_title('Loss over Iterations')\n",
    "ax_loss.plot(history_of_precision[1])\n",
    "\n",
    "# ax_roc = fig.add_subplot(313)\n",
    "# ax_roc.set_title('ROC over Iterations')\n",
    "# ax_roc.plot(np.array(histroy_of_roc)[:,1])\n",
    "\n",
    "fig.canvas.draw()\n",
    "plt.show()\n",
    "# plt.savefig(fig_path + \"bd_oh_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, T_test = shuffleXY(X_val, T_val)\n",
    "X_t = [construct_X(seqs_dicts[0], X_test, cutoff, n_gram_size, dimensions[0], 2000, 0),\n",
    "       construct_X(seqs_dicts[1], X_test, cutoff, n_gram_size, dimensions[1], 2000, 0)]\n",
    "T_t = np.array(T_test[0: 2000]).reshape(2000,cutoff,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value :  -0.332252  Max value :  0.250309\n",
      "Binding site index [probability]\n",
      "114 [ 0.19274254]\n",
      "118 [ 0.18603942]\n",
      "124 [ 0.17423834]\n",
      "490 [-0.1914417]\n",
      "494 [-0.1914417]\n",
      "500 [-0.1914417]\n",
      "Output shape :  (1, 706, 1)\n",
      "Positive predictions :  55.0\n"
     ]
    }
   ],
   "source": [
    "x_t,y_t = randomSample(X_t, T_t)\n",
    "output = model.predict(x_t)\n",
    "print (\"Min value : \", np.min(output[0]),\" Max value : \",np.max(output[0]))\n",
    "\n",
    "print (\"Binding site index [probability]\")\n",
    "for i in range(cutoff):\n",
    "    if y_t[0][i] == 1:\n",
    "        print (i, output[0][i])\n",
    "\n",
    "print (\"Output shape : \", output.shape)\n",
    "print (\"Positive predictions : \", np.sum((output.ravel() > 0) * 1.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print ((output.ravel() > 0) * 1.0) # bd_oh_rp_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.\n",
      "  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.\n",
      "  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print ((output.ravel() > 0) * 1.0) # bd_w2v_rp_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print ((output.ravel() > 0) * 1.0) # bd_oh_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "metal-binding-prediction/Tian's/ProtVec_RNN.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "467px",
    "left": "964.4px",
    "right": "20px",
    "top": "214px",
    "width": "349px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
