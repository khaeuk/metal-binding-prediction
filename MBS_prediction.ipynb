{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = 'userName'\n",
    "metal = 'ZN'\n",
    "model_name = metal+\"_Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# shared result file\n",
    "output_file = './logs/results.txt'\n",
    "hist_path = model_path = fig_path = './logs/'\n",
    "dict_path = './dictionaries/'\n",
    "\n",
    "print (\"Done\")\n",
    "print (\"  Filepath set to ./logs/\")\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Importing modules...\", end=' ')\n",
    "import modules\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./datasets/Metal_all_20180601_predicted.parquet')\n",
    "\n",
    "\n",
    "# Extract the metal\n",
    "df_metal = df.loc[df['metalPrediction'] == metal]\n",
    "\n",
    "seqs = np.array(df_metal.sequence)\n",
    "target = np.array(df_metal.fingerprint)\n",
    "cluster_numbers = np.array(df_metal.clusterNumber90)\n",
    "\n",
    "print (\"Done [\" + metal + \"]\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "import json\n",
    "from proteinSequenceEncoder import property_encoder, blosum62_encoder \n",
    "AMINO_ACIDS21 = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \\\n",
    "                 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "train_cluster, val_cluster = cluster_numbers[:split], cluster_numbers[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator\n",
    "Choose one encoding method and adjust input/output shape to match the model\n",
    "\n",
    "- <font color=blue>FOFE Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dic_fofe = {}\n",
    "with open(dict_path + \"vocab_dict_fofe\", 'r') as fp:\n",
    "        vocab_dic_fofe = json.load(fp)\n",
    "\n",
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': vocab_dic_fofe}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': vocab_dic_fofe}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (800,),\n",
    "               'label_shape': (706, ),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.FOFEGenerator(**train_args, **common_args)\n",
    "val_gen = modules.FOFEGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T19:07:50.137568Z",
     "start_time": "2018-06-12T19:07:50.133579Z"
    }
   },
   "source": [
    "- <font color=blue>One-hot Encoding</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T19:13:29.290555Z",
     "start_time": "2018-06-12T19:13:27.360287Z"
    }
   },
   "source": [
    "seqs_dict_onehot = {}\n",
    "with open(dict_path + \"seqs_dict_onehot\", 'r') as fp:\n",
    "        seqs_dict_onehot = json.load(fp)\n",
    "\n",
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_onehot, \n",
    "              'cluster_numbers': train_cluster}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_onehot, \n",
    "            'cluster_numbers': val_cluster}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1)}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>ProtVec Encoding</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T19:13:32.749896Z",
     "start_time": "2018-06-12T19:13:30.385403Z"
    }
   },
   "source": [
    "seqs_dict_w2v = {}\n",
    "with open(dict_path + \"seq_n_gram_to_vec_dict_w_UX\", 'r') as fp:\n",
    "        seqs_dict_w2v = json.load(fp)\n",
    "\n",
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_w2v,\n",
    "              'cluster_numbers': train_cluster}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_w2v, \n",
    "            'cluster_numbers': val_cluster}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 100),\n",
    "               'label_shape': (706, 1)}\n",
    "\n",
    "train_gen = modules.ProtVecGenerator(**train_args, **common_args)\n",
    "val_gen = modules.ProtVecGenerator(**val_args, **common_args)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Property Encoding</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T19:13:38.416692Z",
     "start_time": "2018-06-12T19:13:36.468658Z"
    }
   },
   "source": [
    "seqs_property = {}\n",
    "for aa in AMINO_ACIDS21:\n",
    "    seqs_property[aa] = property_encoder(aa)\n",
    "\n",
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_property,\n",
    "              'cluster_numbers': train_cluster}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_property, \n",
    "            'cluster_numbers': val_cluster}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 7),\n",
    "               'label_shape': (706, 1)}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Blosum62 Encoding</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T19:13:41.870129Z",
     "start_time": "2018-06-12T19:13:39.962161Z"
    }
   },
   "source": [
    "seqs_blosum62 = {}\n",
    "for aa in AMINO_ACIDS21:\n",
    "    seqs_blosum62[aa] = blosum62_encoder(aa)\n",
    "\n",
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_blosum62,\n",
    "              'cluster_numbers': train_cluster}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_blosum62, \n",
    "            'cluster_numbers': val_cluster}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1)}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- <font color=blue>CNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ProtVec:100, One-hot:20, blosum62:20, property:7\n",
    "dimension = 800\n",
    "cutoff = 706\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Convolution1D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Reshape, Embedding, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "input_shape = (dimension,)\n",
    "\n",
    "input_0 = Input(shape=input_shape, dtype='float32')\n",
    "input_0_reshape = Reshape((1,dimension,1), input_shape=(dimension,))(input_0)\n",
    "conv2d_3 = Conv2D(8, (1, 3), padding='same')(input_0_reshape)\n",
    "conv2d_5 = Conv2D(8, (1, 5), padding='same')(input_0_reshape)\n",
    "conv2d_7 = Conv2D(8, (1, 7), padding='same')(input_0_reshape)\n",
    "\n",
    "x = keras.layers.concatenate([conv2d_3,conv2d_5,conv2d_7])\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(cutoff, activation='relu')(x)\n",
    "output_0 = Dense(cutoff, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_0, outputs=output_0)                              \n",
    "# end of the MODEL\n",
    "\n",
    "sgd = SGD(lr = 0.08, momentum = 0.9, decay = 0, nesterov = False)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Threshold: mean + factor * std</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor = 2.33\n",
    "def threshold_func(y_in):\n",
    "    factor = 2.33\n",
    "    y_out = np.zeros_like(y_in)\n",
    "    for i in range(y_in.shape[0]):\n",
    "        th= np.mean(y_in[i]) + factor * np.std(y_in[i])\n",
    "        y_out[i] = (y_in[i] > th)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Metric: F1 score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cb = modules.F1_history(threshold_func)\n",
    "\n",
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [cb], \n",
    "              'post_train_args': {'user': user, \n",
    "                                  'model': model_name, \n",
    "                                  'result': output_file, \n",
    "                                  'fig_path': fig_path, \n",
    "                                  'optimizer': str(type(model.optimizer)).replace('<class \\'keras.optimizers.', '').replace('\\'>', ''), \n",
    "                                  'optimizer_config' : model.optimizer.get_config(), \n",
    "                                  'loss': model.loss, \n",
    "                                  'factor': factor}}\n",
    "\n",
    "trainer = modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings; \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "trainer.start(epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./models/\" +metal + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./models/\" +metal + \".h5\")\n",
    "print(\"Saved \" + metal +\" model to disk\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# load json and create model\n",
    "json_file = open(\"./models/\" +metal + \".json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./models/\" +metal + \".h5\")\n",
    "print(\"Loaded \" + metal +\" model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
