{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:30:53.291627Z",
     "start_time": "2018-05-03T04:30:53.288619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = 'Zihan'\n",
    "model_name = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:30:56.519561Z",
     "start_time": "2018-05-03T04:30:54.135222Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing global variables... Done\n",
      "  Filepath set to Zihan's directory\n",
      "Importing modules... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zenzeehong/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Reading data from disk... Done\n",
      "Loading dictionaries... Done\n",
      "Performing cross validation split... Done\n",
      "  Ratio : 0.9\n",
      "  Train_range : 0 - 20504\n",
      "  Val_range : 20505 - 22783\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Filepaths\n",
    "dict_path = './' + user + '/dictionaries/'\n",
    "model_path = './' + user + '/models/'\n",
    "hist_path = './' + user + '/histories/'\n",
    "fig_path = './' + user + '/figs/'\n",
    "\n",
    "# shared result file\n",
    "output_file = './results.txt'\n",
    "\n",
    "print (\"Done\")\n",
    "print (\"  Filepath set to \" + user + \"'s directory\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Importing modules...\", end=' ')\n",
    "import modules\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./Tian/Metal_all_20180116.snappy.parquet')\n",
    "\n",
    "# Extract zinc-binded, single-chained protein sequences\n",
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "target = np.array(df_zn_single.fingerprint)\n",
    "\n",
    "del df,df_zn,df_zn_single\n",
    "\n",
    "# Remove seqs containing 'U' and 'X'\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] or 'U' in seqs[i]:\n",
    "        rows_to_delete.append(i)        \n",
    "        \n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Loading dictionaries...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# FOFE\n",
    "vocab_dic_fofe = {}\n",
    "with open(dict_path + \"vocab_dict_fofe\", 'r') as fp:\n",
    "        vocab_dic_fofe = json.load(fp)\n",
    "\n",
    "# # ProtVec\n",
    "# seqs_dict_w2v = {}\n",
    "# with open(dict_path + \"seq_n_gram_to_vec_dict_w_UX\", 'r') as fp:\n",
    "#         seqs_dict_w2v = json.load(fp)\n",
    "\n",
    "# # One-hot\n",
    "# seqs_dict_onehot = {}\n",
    "# with open(dict_path + \"seqs_dict_onehot\", 'r') as fp:\n",
    "#         seqs_dict_onehot = json.load(fp)\n",
    "\n",
    "# # property\n",
    "# # blosum62\n",
    "# from proteinSequenceEncoder import property_encoder, blosum62_encoder \n",
    "# AMINO_ACIDS21 = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \\\n",
    "#                  'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "# seqs_property = {}\n",
    "# seqs_blosum62 = {}\n",
    "# seqs_onehot_blosum = {}\n",
    "\n",
    "# for aa in AMINO_ACIDS21:\n",
    "#     seqs_property[aa] = property_encoder(aa)\n",
    "#     seqs_blosum62[aa] = blosum62_encoder(aa)\n",
    "#     if aa != 'X' and aa !='U':\n",
    "#         seqs_onehot_blosum[aa] = seqs_dict_onehot[aa] + blosum62_encoder(aa)[0]\n",
    "\n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- <font color=blue>FOFE Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': vocab_dic_fofe}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': vocab_dic_fofe}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (800,),\n",
    "               'label_shape': (706,),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.FOFEGenerator(**train_args, **common_args)\n",
    "val_gen = modules.FOFEGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seqs_dict_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f60b7c092289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_args = {'sequences': train_seqs,\n\u001b[1;32m      2\u001b[0m               \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               'translator': seqs_dict_onehot}\n\u001b[0m\u001b[1;32m      4\u001b[0m val_args = {'sequences': val_seqs,\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seqs_dict_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_onehot}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_onehot}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_dict_w2v}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_dict_w2v}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 100),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.ProtVecGenerator(**train_args, **common_args)\n",
    "val_gen = modules.ProtVecGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_property}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_property}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 7),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_blosum62}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_blosum62}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 20),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>One-hot + Blosum62 Encodings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:31:00.150219Z",
     "start_time": "2018-05-03T04:31:00.143202Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': seqs_onehot_blosum}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': seqs_onehot_blosum}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (706, 40),\n",
    "               'label_shape': (706, 1),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = modules.OneHotGenerator(**train_args, **common_args)\n",
    "val_gen = modules.OneHotGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- <font color=blue>CNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:31:04.314391Z",
     "start_time": "2018-05-03T04:31:03.807947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 800)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 800, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 800, 2)    8           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 800, 2)    12          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 800, 2)    16          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 800, 6)    0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 800, 6)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4800)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 706)          3389506     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 706)          499142      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,888,684\n",
      "Trainable params: 3,888,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zenzeehong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 3), padding=\"same\")`\n",
      "/Users/zenzeehong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 5), padding=\"same\")`\n",
      "/Users/zenzeehong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 7), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# ProtVec:100, One-hot:20, blosum62:20, property:7\n",
    "dimension = 800\n",
    "cutoff = 706\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Reshape, Embedding, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "input_shape = (dimension,)\n",
    "lstm_size = 64\n",
    "\n",
    "input_0 = Input(shape=input_shape, dtype='float32')\n",
    "input_0_reshape = Reshape((1,dimension,1), input_shape=(dimension,))(input_0)\n",
    "conv2d_3 = Convolution2D(2, 1, 3, border_mode='same')(input_0_reshape)\n",
    "conv2d_5 = Convolution2D(2, 1, 5, border_mode='same')(input_0_reshape)\n",
    "conv2d_7 = Convolution2D(2, 1, 7, border_mode='same')(input_0_reshape)\n",
    "\n",
    "x = keras.layers.concatenate([conv2d_3,conv2d_5,conv2d_7])\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(cutoff, activation='relu')(x)\n",
    "output_0 = Dense(cutoff, activation='softmax')(x)\n",
    "#output_0_reshape = Reshape((cutoff,1), input_shape=(cutoff,))(output_0)\n",
    "\n",
    "#model = Model(inputs=input_0, outputs=output_0_reshape)\n",
    "model = Model(inputs=input_0, outputs=output_0)\n",
    "# end of the MODEL\n",
    "\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Threshold: mean+2.33*std</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:31:08.077301Z",
     "start_time": "2018-05-03T04:31:08.071286Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_func(y_in):\n",
    "    factor = 2.33\n",
    "    y_out = np.zeros_like(y_in)\n",
    "    for i in range(y_in.shape[0]):\n",
    "        th= np.mean(y_in[i]) + factor * np.std(y_in[i])\n",
    "        y_out[i] = (y_in[i] > th)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Metric: F1 score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:31:11.757091Z",
     "start_time": "2018-05-03T04:31:11.751074Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback initialized.\n",
      "Assigning validation generator... Done\n",
      "Matching input shape... Done\n",
      "Matching output shape... Done\n",
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "cb = modules.F1_history(threshold_func)\n",
    "\n",
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [cb], \n",
    "              'post_train_args': {'user': user, \n",
    "                                  'model': model_name, \n",
    "                                  'result': output_file, \n",
    "                                  'fig_path': fig_path}}\n",
    "\n",
    "trainer = modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T04:38:07.699381Z",
     "start_time": "2018-05-03T04:31:15.473977Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "(100, 706)\n",
      "(100, 706)(100, 706)(100, 706)(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "\n",
      "(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)(100, 706)\n",
      "\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  1/205 [..............................] - ETA: 37:07 - loss: nan - acc: 0.0100(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  2/205 [..............................] - ETA: 20:20 - loss: nan - acc: 0.0050(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  3/205 [..............................] - ETA: 14:54 - loss: nan - acc: 0.0033(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  4/205 [..............................] - ETA: 12:11 - loss: nan - acc: 0.0025(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  5/205 [..............................] - ETA: 10:33 - loss: nan - acc: 0.0020(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  6/205 [..............................] - ETA: 9:25 - loss: nan - acc: 0.0067 (100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  7/205 [>.............................] - ETA: 8:36 - loss: nan - acc: 0.0071(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  8/205 [>.............................] - ETA: 8:03 - loss: nan - acc: 0.0075(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "  9/205 [>.............................] - ETA: 7:38 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 10/205 [>.............................] - ETA: 7:15 - loss: nan - acc: 0.0070(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 11/205 [>.............................] - ETA: 6:56 - loss: nan - acc: 0.0073(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 12/205 [>.............................] - ETA: 6:41 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 13/205 [>.............................] - ETA: 6:27 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 14/205 [=>............................] - ETA: 6:18 - loss: nan - acc: 0.0057(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 15/205 [=>............................] - ETA: 6:08 - loss: nan - acc: 0.0053(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 16/205 [=>............................] - ETA: 6:01 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 17/205 [=>............................] - ETA: 5:52 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 18/205 [=>............................] - ETA: 5:44 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 19/205 [=>............................] - ETA: 5:34 - loss: nan - acc: 0.0058(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 20/205 [=>............................] - ETA: 5:25 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 21/205 [==>...........................] - ETA: 5:20 - loss: nan - acc: 0.0057(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 22/205 [==>...........................] - ETA: 5:14 - loss: nan - acc: 0.0055(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 23/205 [==>...........................] - ETA: 5:07 - loss: nan - acc: 0.0057(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 24/205 [==>...........................] - ETA: 5:00 - loss: nan - acc: 0.0054(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 25/205 [==>...........................] - ETA: 4:54 - loss: nan - acc: 0.0056(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 26/205 [==>...........................] - ETA: 4:51 - loss: nan - acc: 0.0054(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 27/205 [==>...........................] - ETA: 4:45 - loss: nan - acc: 0.0052(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 28/205 [===>..........................] - ETA: 4:40 - loss: nan - acc: 0.0050(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 29/205 [===>..........................] - ETA: 4:38 - loss: nan - acc: 0.0048(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 30/205 [===>..........................] - ETA: 4:34 - loss: nan - acc: 0.0047(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 31/205 [===>..........................] - ETA: 4:31 - loss: nan - acc: 0.0052(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 32/205 [===>..........................] - ETA: 4:28 - loss: nan - acc: 0.0050(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 33/205 [===>..........................] - ETA: 4:24 - loss: nan - acc: 0.0048(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 34/205 [===>..........................] - ETA: 4:20 - loss: nan - acc: 0.0047(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 35/205 [====>.........................] - ETA: 4:16 - loss: nan - acc: 0.0051(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 36/205 [====>.........................] - ETA: 4:12 - loss: nan - acc: 0.0050(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 37/205 [====>.........................] - ETA: 4:08 - loss: nan - acc: 0.0051(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 38/205 [====>.........................] - ETA: 4:05 - loss: nan - acc: 0.0053(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 39/205 [====>.........................] - ETA: 4:02 - loss: nan - acc: 0.0054(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 40/205 [====>.........................] - ETA: 3:59 - loss: nan - acc: 0.0052(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 41/205 [=====>........................] - ETA: 3:56 - loss: nan - acc: 0.0051(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 42/205 [=====>........................] - ETA: 3:53 - loss: nan - acc: 0.0052(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 43/205 [=====>........................] - ETA: 3:50 - loss: nan - acc: 0.0051(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 44/205 [=====>........................] - ETA: 3:47 - loss: nan - acc: 0.0050(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 45/205 [=====>........................] - ETA: 3:44 - loss: nan - acc: 0.0053(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 46/205 [=====>........................] - ETA: 3:41 - loss: nan - acc: 0.0054(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 47/205 [=====>........................] - ETA: 3:38 - loss: nan - acc: 0.0055(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 48/205 [======>.......................] - ETA: 3:38 - loss: nan - acc: 0.0054(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 49/205 [======>.......................] - ETA: 3:37 - loss: nan - acc: 0.0057(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 50/205 [======>.......................] - ETA: 3:35 - loss: nan - acc: 0.0056(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 51/205 [======>.......................] - ETA: 3:32 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 52/205 [======>.......................] - ETA: 3:30 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 53/205 [======>.......................] - ETA: 3:28 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 54/205 [======>.......................] - ETA: 3:26 - loss: nan - acc: 0.0059(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 55/205 [=======>......................] - ETA: 3:24 - loss: nan - acc: 0.0058(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 56/205 [=======>......................] - ETA: 3:22 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 57/205 [=======>......................] - ETA: 3:19 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 58/205 [=======>......................] - ETA: 3:17 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 59/205 [=======>......................] - ETA: 3:15 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 60/205 [=======>......................] - ETA: 3:13 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 61/205 [=======>......................] - ETA: 3:11 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 62/205 [========>.....................] - ETA: 3:09 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 63/205 [========>.....................] - ETA: 3:07 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 64/205 [========>.....................] - ETA: 3:05 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 65/205 [========>.....................] - ETA: 3:04 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 66/205 [========>.....................] - ETA: 3:02 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 67/205 [========>.....................] - ETA: 3:01 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 68/205 [========>.....................] - ETA: 2:59 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 69/205 [=========>....................] - ETA: 2:57 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 70/205 [=========>....................] - ETA: 2:55 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 71/205 [=========>....................] - ETA: 2:53 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 72/205 [=========>....................] - ETA: 2:51 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 73/205 [=========>....................] - ETA: 2:50 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74/205 [=========>....................] - ETA: 2:48 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 75/205 [=========>....................] - ETA: 2:46 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 76/205 [==========>...................] - ETA: 2:45 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 77/205 [==========>...................] - ETA: 2:43 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 78/205 [==========>...................] - ETA: 2:41 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 79/205 [==========>...................] - ETA: 2:40 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 80/205 [==========>...................] - ETA: 2:38 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 81/205 [==========>...................] - ETA: 2:37 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 82/205 [===========>..................] - ETA: 2:35 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 83/205 [===========>..................] - ETA: 2:33 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 84/205 [===========>..................] - ETA: 2:32 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 85/205 [===========>..................] - ETA: 2:30 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 86/205 [===========>..................] - ETA: 2:29 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 87/205 [===========>..................] - ETA: 2:27 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 88/205 [===========>..................] - ETA: 2:25 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 89/205 [============>.................] - ETA: 2:24 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 90/205 [============>.................] - ETA: 2:22 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 91/205 [============>.................] - ETA: 2:21 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 92/205 [============>.................] - ETA: 2:19 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 93/205 [============>.................] - ETA: 2:18 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 94/205 [============>.................] - ETA: 2:16 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 95/205 [============>.................] - ETA: 2:15 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 96/205 [=============>................] - ETA: 2:13 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 97/205 [=============>................] - ETA: 2:12 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 98/205 [=============>................] - ETA: 2:11 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      " 99/205 [=============>................] - ETA: 2:09 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "100/205 [=============>................] - ETA: 2:08 - loss: nan - acc: 0.0059(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "101/205 [=============>................] - ETA: 2:07 - loss: nan - acc: 0.0059(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "102/205 [=============>................] - ETA: 2:05 - loss: nan - acc: 0.0059(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "103/205 [==============>...............] - ETA: 2:04 - loss: nan - acc: 0.0059(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "104/205 [==============>...............] - ETA: 2:03 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "105/205 [==============>...............] - ETA: 2:01 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "106/205 [==============>...............] - ETA: 2:00 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "107/205 [==============>...............] - ETA: 1:58 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "108/205 [==============>...............] - ETA: 1:57 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "109/205 [==============>...............] - ETA: 1:56 - loss: nan - acc: 0.0060(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "110/205 [===============>..............] - ETA: 1:54 - loss: nan - acc: 0.0061(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "111/205 [===============>..............] - ETA: 1:53 - loss: nan - acc: 0.0062(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "112/205 [===============>..............] - ETA: 1:51 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "113/205 [===============>..............] - ETA: 1:50 - loss: nan - acc: 0.0063(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "114/205 [===============>..............] - ETA: 1:49 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "115/205 [===============>..............] - ETA: 1:48 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "116/205 [===============>..............] - ETA: 1:46 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "117/205 [================>.............] - ETA: 1:45 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "118/205 [================>.............] - ETA: 1:43 - loss: nan - acc: 0.0064(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "119/205 [================>.............] - ETA: 1:42 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "120/205 [================>.............] - ETA: 1:41 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "121/205 [================>.............] - ETA: 1:39 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "122/205 [================>.............] - ETA: 1:38 - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "123/205 [=================>............] - ETA: 1:37 - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "124/205 [=================>............] - ETA: 1:36 - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "125/205 [=================>............] - ETA: 1:34 - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "126/205 [=================>............] - ETA: 1:33 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "127/205 [=================>............] - ETA: 1:32 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "128/205 [=================>............] - ETA: 1:30 - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "129/205 [=================>............] - ETA: 1:29 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "130/205 [==================>...........] - ETA: 1:28 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "131/205 [==================>...........] - ETA: 1:27 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "132/205 [==================>...........] - ETA: 1:25 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "133/205 [==================>...........] - ETA: 1:24 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "134/205 [==================>...........] - ETA: 1:23 - loss: nan - acc: 0.0069(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "135/205 [==================>...........] - ETA: 1:22 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "136/205 [==================>...........] - ETA: 1:20 - loss: nan - acc: 0.0069(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "137/205 [===================>..........] - ETA: 1:19 - loss: nan - acc: 0.0069(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "138/205 [===================>..........] - ETA: 1:18 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "139/205 [===================>..........] - ETA: 1:16 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "140/205 [===================>..........] - ETA: 1:15 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "141/205 [===================>..........] - ETA: 1:14 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "142/205 [===================>..........] - ETA: 1:13 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "143/205 [===================>..........] - ETA: 1:12 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "144/205 [====================>.........] - ETA: 1:10 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "145/205 [====================>.........] - ETA: 1:09 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "146/205 [====================>.........] - ETA: 1:08 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "147/205 [====================>.........] - ETA: 1:07 - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "148/205 [====================>.........] - ETA: 1:05 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "149/205 [====================>.........] - ETA: 1:04 - loss: nan - acc: 0.0068(100, 706)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 706)\n",
      " F1 0.0\n",
      "150/205 [====================>.........] - ETA: 1:03 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "151/205 [=====================>........] - ETA: 1:02 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "152/205 [=====================>........] - ETA: 1:01 - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "153/205 [=====================>........] - ETA: 59s - loss: nan - acc: 0.0067 (100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "154/205 [=====================>........] - ETA: 58s - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "155/205 [=====================>........] - ETA: 57s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "156/205 [=====================>........] - ETA: 56s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "157/205 [=====================>........] - ETA: 55s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "158/205 [======================>.......] - ETA: 53s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "159/205 [======================>.......] - ETA: 52s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "160/205 [======================>.......] - ETA: 51s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "161/205 [======================>.......] - ETA: 50s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "162/205 [======================>.......] - ETA: 49s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "163/205 [======================>.......] - ETA: 47s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "164/205 [=======================>......] - ETA: 46s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "165/205 [=======================>......] - ETA: 45s - loss: nan - acc: 0.0067(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "166/205 [=======================>......] - ETA: 44s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "167/205 [=======================>......] - ETA: 43s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "168/205 [=======================>......] - ETA: 42s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "169/205 [=======================>......] - ETA: 40s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "170/205 [=======================>......] - ETA: 39s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "171/205 [========================>.....] - ETA: 38s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "172/205 [========================>.....] - ETA: 37s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "173/205 [========================>.....] - ETA: 36s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "174/205 [========================>.....] - ETA: 35s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "175/205 [========================>.....] - ETA: 34s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "176/205 [========================>.....] - ETA: 32s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "177/205 [========================>.....] - ETA: 31s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "178/205 [=========================>....] - ETA: 30s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "179/205 [=========================>....] - ETA: 29s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "180/205 [=========================>....] - ETA: 28s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "181/205 [=========================>....] - ETA: 27s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "182/205 [=========================>....] - ETA: 25s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "183/205 [=========================>....] - ETA: 24s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "184/205 [=========================>....] - ETA: 23s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "185/205 [==========================>...] - ETA: 22s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "186/205 [==========================>...] - ETA: 21s - loss: nan - acc: 0.0066(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "187/205 [==========================>...] - ETA: 20s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "188/205 [==========================>...] - ETA: 19s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "189/205 [==========================>...] - ETA: 17s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "190/205 [==========================>...] - ETA: 16s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "191/205 [==========================>...] - ETA: 15s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "192/205 [===========================>..] - ETA: 14s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "193/205 [===========================>..] - ETA: 13s - loss: nan - acc: 0.0065(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "194/205 [===========================>..] - ETA: 12s - loss: nan - acc: 0.0065(100, 706)\n",
      " F1 0.0\n",
      "195/205 [===========================>..] - ETA: 11s - loss: nan - acc: 0.0066(100, 706)\n",
      " F1 0.0\n",
      "196/205 [===========================>..] - ETA: 10s - loss: nan - acc: 0.0067(100, 706)\n",
      " F1 0.0\n",
      "197/205 [===========================>..] - ETA: 8s - loss: nan - acc: 0.0068 (100, 706)\n",
      " F1 0.0\n",
      "198/205 [===========================>..] - ETA: 7s - loss: nan - acc: 0.0068(100, 706)\n",
      " F1 0.0\n",
      "199/205 [============================>.] - ETA: 6s - loss: nan - acc: 0.0068(100, 706)\n",
      " F1 0.0\n",
      "200/205 [============================>.] - ETA: 5s - loss: nan - acc: 0.0067(100, 706)\n",
      " F1 0.0\n",
      "201/205 [============================>.] - ETA: 4s - loss: nan - acc: 0.0067(100, 706)\n",
      " F1 0.0\n",
      "202/205 [============================>.] - ETA: 3s - loss: nan - acc: 0.0068(100, 706)\n",
      " F1 0.0\n",
      "203/205 [============================>.] - ETA: 2s - loss: nan - acc: 0.0068(100, 706)\n",
      " F1 0.0\n",
      "204/205 [============================>.] - ETA: 1s - loss: nan - acc: 0.0068(100, 706)\n",
      "(100, 706)(100, 706)(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "\n",
      "(100, 706)(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      " F1 0.0\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)\n",
      "(100, 706)(100, 706)(100, 706)(100, 706)\n",
      "\n",
      "\n",
      "\n",
      "205/205 [==============================] - 235s 1s/step - loss: nan - acc: 0.0068 - val_loss: nan - val_acc: 0.0064\n",
      "[End of Training]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZLU+P/wbH2afhB5wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings; \n",
    "warnings.simplefilter('ignore')\n",
    "trainer.start(epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
