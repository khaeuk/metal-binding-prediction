{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:16:49.299790Z",
     "start_time": "2018-05-18T01:16:49.296788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = 'Zihan'\n",
    "model_name = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:16:52.007922Z",
     "start_time": "2018-05-18T01:16:51.176627Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing global variables... Done\n",
      "  Filepath set to [Zihan]'s directory\n",
      "Importing modules... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Reading data from disk... Done\n",
      "Loading dictionaries... Done\n",
      "Performing cross validation split... Done\n",
      "  Ratio : 0.9\n",
      "  Train_range : 0 - 20502\n",
      "  Val_range : 20503 - 22781\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Filepaths\n",
    "dict_path = './' + user + '/dictionaries/'\n",
    "model_path = './' + user + '/models/'\n",
    "hist_path = './' + user + '/histories/'\n",
    "fig_path = './' + user + '/figs/'\n",
    "\n",
    "# shared result file\n",
    "output_file = './results.txt'\n",
    "\n",
    "print (\"Done\")\n",
    "print (\"  Filepath set to [\" + user + \"]'s directory\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Importing modules...\", end=' ')\n",
    "import modules\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./Tian/Metal_all_20180116.snappy.parquet')\n",
    "\n",
    "# Extract zinc-binded, single-chained protein sequences\n",
    "df_zn = df.loc[df['ligandId'] == 'ZN']\n",
    "df_zn_single = df_zn.loc[df_zn['interactingChains'] == 1]\n",
    "seqs = np.array(df_zn_single.sequence)\n",
    "target = np.array(df_zn_single.fingerprint)\n",
    "cluster_numbers = np.array(df_zn_single.clusterNumber90)\n",
    "\n",
    "del df,df_zn,df_zn_single\n",
    "\n",
    "# Remove seqs containing 'U' and 'X'\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] or 'U' in seqs[i] or np.isnan(cluster_numbers[i]):\n",
    "        rows_to_delete.append(i) \n",
    "\n",
    "        \n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "cluster_numbers = np.delete(cluster_numbers, rows_to_delete)\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Loading dictionaries...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# FOFE\n",
    "vocab_dic_fofe = {}\n",
    "with open(dict_path + \"vocab_dict_fofe\", 'r') as fp:\n",
    "        vocab_dic_fofe = json.load(fp)\n",
    "\n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "train_cluster, val_cluster = cluster_numbers[:split], cluster_numbers[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- <font color=blue>FOFE Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': vocab_dic_fofe,\n",
    "              'cluster_numbers': train_cluster}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': vocab_dic_fofe,\n",
    "            'cluster_numbers': val_cluster}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (800,),\n",
    "               'label_shape': (706, ),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen_0 = modules.FOFEGenerator(**train_args, **common_args)\n",
    "val_gen_0 = modules.FOFEGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = train_gen_0\n",
    "val_gen = val_gen_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- <font color=blue>CNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:16:59.142208Z",
     "start_time": "2018-05-18T01:16:58.517951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 800)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 800, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 800, 2)    8           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 800, 2)    12          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 800, 2)    16          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 800, 6)    0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 800, 6)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4800)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 706)          3389506     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 706)          499142      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,888,684\n",
      "Trainable params: 3,888,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 3), padding=\"same\")`\n",
      "D:\\Software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 5), padding=\"same\")`\n",
      "D:\\Software\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 7), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# ProtVec:100, One-hot:20, blosum62:20, property:7\n",
    "dimension = 800\n",
    "cutoff = 706\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Reshape, Embedding, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "input_shape = (dimension,)\n",
    "\n",
    "input_0 = Input(shape=input_shape, dtype='float32')\n",
    "input_0_reshape = Reshape((1,dimension,1), input_shape=(dimension,))(input_0)\n",
    "conv2d_3 = Convolution2D(2, 1, 3, border_mode='same')(input_0_reshape)\n",
    "conv2d_5 = Convolution2D(2, 1, 5, border_mode='same')(input_0_reshape)\n",
    "conv2d_7 = Convolution2D(2, 1, 7, border_mode='same')(input_0_reshape)\n",
    "\n",
    "x = keras.layers.concatenate([conv2d_3,conv2d_5,conv2d_7])\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(cutoff, activation='relu')(x)\n",
    "output_0 = Dense(cutoff, activation='softmax')(x)\n",
    "#output_0_reshape = Reshape((cutoff,1), input_shape=(cutoff,))(output_0)\n",
    "\n",
    "#model = Model(inputs=input_0, outputs=output_0_reshape)\n",
    "model = Model(inputs=input_0, outputs=output_0)                              \n",
    "# end of the MODEL\n",
    "\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Threshold: mean+2.33*std</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:17:01.005581Z",
     "start_time": "2018-05-18T01:17:00.998117Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_func(y_in):\n",
    "    factor = 2.33\n",
    "    y_out = np.zeros_like(y_in)\n",
    "    for i in range(y_in.shape[0]):\n",
    "        th= np.mean(y_in[i]) + factor * np.std(y_in[i])\n",
    "        y_out[i] = (y_in[i] > th)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>Metric: F1 score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:17:02.876029Z",
     "start_time": "2018-05-18T01:17:02.869554Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback initialized.\n",
      "Assigning validation generator... Done\n",
      "Matching input shape... Done\n",
      "Matching output shape... Done\n",
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "cb = modules.F1_history(threshold_func)\n",
    "\n",
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [cb], \n",
    "              'post_train_args': {'user': user, \n",
    "                                  'model': model_name, \n",
    "                                  'result': output_file, \n",
    "                                  'fig_path': fig_path}}\n",
    "\n",
    "trainer = modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T01:31:12.869734Z",
     "start_time": "2018-05-18T01:17:07.263749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 61s 300ms/step - loss: 14.9843 - acc: 0.1300\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 10.3187 - acc: 0.1895\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 9.0277 - acc: 0.2030\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 8.4008 - acc: 0.2107\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 7.9732 - acc: 0.2177\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 7.6674 - acc: 0.2211\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 8.0799 - acc: 0.2165\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 60s 291ms/step - loss: 7.5921 - acc: 0.2194\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 60s 290ms/step - loss: 7.3649 - acc: 0.2172\n",
      "Epoch 10/10\n",
      "176/205 [========================>.....] - ETA: 8s - loss: 7.1992 - acc: 0.2226"
     ]
    }
   ],
   "source": [
    "import warnings; \n",
    "warnings.simplefilter('ignore')\n",
    "trainer.start(epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
