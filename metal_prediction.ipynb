{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:14:49.119600Z",
     "start_time": "2018-06-05T06:14:49.116128Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = 'X'\n",
    "model_name = 'metal_prediction_CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:14:58.588664Z",
     "start_time": "2018-06-05T06:14:49.541851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing global variables... Done\n",
      "  Filepath set to ./logs/\n",
      "Importing modules... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Reading data from disk... {'CA', 'ZN', 'NI', 'CO', 'FE', 'CU', 'MG', 'MN'}\n",
      "Done\n",
      "Loading dictionaries... Done\n",
      "Performing cross validation split... Done\n",
      "  Ratio : 0.9\n",
      "  Train_range : 0 - 52385\n",
      "  Val_range : 52386 - 58206\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "print (\"Initializing global variables...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Filepaths\n",
    "output_file = './logs/results.txt'\n",
    "hist_path = model_path = fig_path = './logs/'\n",
    "dict_path = './dictionaries/'\n",
    "\n",
    "print (\"Done\")\n",
    "print (\"  Filepath set to ./logs/\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Importing modules...\", end=' ')\n",
    "import metal_prediction_modules\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Reading data from disk...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./datasets/Metal_all_20180601.parquet')\n",
    "seqs = np.array(df.sequence)\n",
    "target = np.array(df.ligandId)\n",
    "cluster_numbers = np.array(df.clusterNumber90)\n",
    "\n",
    "print (set(target))\n",
    "\n",
    "label_dict ={}\n",
    "for i, j in enumerate(set(df.ligandId)):\n",
    "    label_dict[j] = i\n",
    "\n",
    "for i in range(target.shape[0]):\n",
    "    target[i] = [label_dict[target[i]]]\n",
    "    \n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Loading dictionaries...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# FOFE\n",
    "vocab_dic_fofe = {}\n",
    "with open(dict_path + \"vocab_dict_fofe\", 'r') as fp:\n",
    "        vocab_dic_fofe = json.load(fp)\n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "print (\"Performing cross validation split...\", end=' ')\n",
    "ratio = 0.9\n",
    "split = int(ratio*len(seqs))\n",
    "train_seqs, val_seqs = seqs[:split], seqs[split:]\n",
    "train_label, val_label = target[:split], target[split:]\n",
    "print (\"Done\")\n",
    "print (\"  Ratio :\", ratio)\n",
    "print (\"  Train_range :\", 0, \"-\", split-1)\n",
    "print (\"  Val_range :\", split, \"-\", len(seqs)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:14:58.694808Z",
     "start_time": "2018-06-05T06:14:58.649178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureChainId</th>\n",
       "      <th>fingerprint</th>\n",
       "      <th>groupNumber</th>\n",
       "      <th>sequence</th>\n",
       "      <th>interactingChains</th>\n",
       "      <th>clusterNumber30</th>\n",
       "      <th>clusterNumber40</th>\n",
       "      <th>clusterNumber50</th>\n",
       "      <th>clusterNumber70</th>\n",
       "      <th>clusterNumber90</th>\n",
       "      <th>clusterNumber95</th>\n",
       "      <th>clusterNumber100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ligandId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "      <td>17606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "      <td>8336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "      <td>4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "      <td>20613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          structureChainId  fingerprint  groupNumber  sequence  \\\n",
       "ligandId                                                         \n",
       "CA                   17606        17606        17606     17606   \n",
       "CO                     759          759          759       759   \n",
       "CU                    2143         2143         2143      2143   \n",
       "FE                    2989         2989         2989      2989   \n",
       "MG                    8336         8336         8336      8336   \n",
       "MN                    4688         4688         4688      4688   \n",
       "NI                    1073         1073         1073      1073   \n",
       "ZN                   20613        20613        20613     20613   \n",
       "\n",
       "          interactingChains  clusterNumber30  clusterNumber40  \\\n",
       "ligandId                                                        \n",
       "CA                    17606            17606            17606   \n",
       "CO                      759              759              759   \n",
       "CU                     2143             2143             2143   \n",
       "FE                     2989             2989             2989   \n",
       "MG                     8336             8336             8336   \n",
       "MN                     4688             4688             4688   \n",
       "NI                     1073             1073             1073   \n",
       "ZN                    20613            20613            20613   \n",
       "\n",
       "          clusterNumber50  clusterNumber70  clusterNumber90  clusterNumber95  \\\n",
       "ligandId                                                                       \n",
       "CA                  17606            17606            17606            17606   \n",
       "CO                    759              759              759              759   \n",
       "CU                   2143             2143             2143             2143   \n",
       "FE                   2989             2989             2989             2989   \n",
       "MG                   8336             8336             8336             8336   \n",
       "MN                   4688             4688             4688             4688   \n",
       "NI                   1073             1073             1073             1073   \n",
       "ZN                  20613            20613            20613            20613   \n",
       "\n",
       "          clusterNumber100  \n",
       "ligandId                    \n",
       "CA                   17606  \n",
       "CO                     759  \n",
       "CU                    2143  \n",
       "FE                    2989  \n",
       "MG                    8336  \n",
       "MN                    4688  \n",
       "NI                    1073  \n",
       "ZN                   20613  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('ligandId').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- <font color=blue>FOFE Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:15:12.566934Z",
     "start_time": "2018-06-05T06:14:58.761301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': train_seqs,\n",
    "              'labels': train_label,\n",
    "              'translator': vocab_dic_fofe}\n",
    "val_args = {'sequences': val_seqs,\n",
    "            'labels': val_label,\n",
    "            'translator': vocab_dic_fofe}\n",
    "common_args = {'batch_size': 100,\n",
    "               'input_shape': (800,),\n",
    "               'label_shape': (8, ),\n",
    "               'shuffle': True}\n",
    "\n",
    "train_gen = metal_prediction_modules.FOFEGenerator(**train_args, **common_args)\n",
    "val_gen = metal_prediction_modules.FOFEGenerator(**val_args, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- <font color=blue>CNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:15:12.886880Z",
     "start_time": "2018-06-05T06:15:12.634886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 3), padding=\"same\")`\n",
      "C:\\Users\\Tian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 5), padding=\"same\")`\n",
      "C:\\Users\\Tian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 7), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# ProtVec:100, One-hot:20, blosum62:20, property:7\n",
    "dimension = 800\n",
    "cutoff = 8\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Reshape, Embedding, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "# Visualization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "input_shape = (dimension,)\n",
    "\n",
    "input_0 = Input(shape=input_shape, dtype='float32')\n",
    "input_0_reshape = Reshape((1,dimension,1), input_shape=(dimension,))(input_0)\n",
    "conv2d_3 = Convolution2D(2, 1, 3, border_mode='same')(input_0_reshape)\n",
    "conv2d_5 = Convolution2D(2, 1, 5, border_mode='same')(input_0_reshape)\n",
    "conv2d_7 = Convolution2D(2, 1, 7, border_mode='same')(input_0_reshape)\n",
    "\n",
    "x = keras.layers.concatenate([conv2d_3,conv2d_5,conv2d_7])\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(cutoff, activation='relu')(x)\n",
    "output_0 = Dense(cutoff, activation='softmax')(x)\n",
    "#output_0_reshape = Reshape((cutoff,1), input_shape=(cutoff,))(output_0)\n",
    "\n",
    "#model = Model(inputs=input_0, outputs=output_0_reshape)\n",
    "model = Model(inputs=input_0, outputs=output_0)                              \n",
    "# end of the MODEL\n",
    "\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:15:12.976631Z",
     "start_time": "2018-06-05T06:15:12.968812Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning validation generator... Done\n",
      "Matching input shape... Done\n",
      "Matching output shape... Done\n",
      "Trainer initialized.\n"
     ]
    }
   ],
   "source": [
    "model_args = {'model': model, \n",
    "              'generators': [train_gen, val_gen], \n",
    "              'callbacks': [], \n",
    "              'post_train_args': {'user': user, \n",
    "                                  'model': model_name, \n",
    "                                  'result': output_file, \n",
    "                                  'fig_path': fig_path}}\n",
    "\n",
    "trainer = metal_prediction_modules.Trainer(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T06:47:36.206846Z",
     "start_time": "2018-06-05T06:39:59.341561Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "523/523 [==============================] - 78s 150ms/step - loss: 0.3396 - acc: 0.8772: 2:00 - loss: 0.2993 - acc: - ETA: 1:37 - loss: 0.3061 - acc: 0.8 - ETA: 1:26 - loss: 0.3147 - acc: 0. - ETA: 1:26 - loss: 0.3139 - ac - ETA: 1:19 - loss: 0.3111 - acc: - ETA: 1:18 - loss: 0.3045 - acc - ETA: 1:16 - loss: 0.3039 - ac - ETA: 1:17 - loss: 0.2980 - acc: 0 - ETA: 1:18 - loss: 0.3019 - acc:  - ETA: 1:15 - loss: 0.30 - ETA: 1:09 - loss: - ETA: 1:05 - loss: 0.3004 - a - ETA: 58s - loss: 0.3123 - acc - ETA: 56s - loss: 0.3139 - - ETA: 55s - loss: 0.31 - ETA: 53s - loss: 0.31 - ETA: 52s - loss: 0.3184 - acc:  - E - ETA: 49s - loss: 0.32 - ETA: 47s - loss: 0.3230 - acc:  - ETA: 46s - loss: 0.3230 - - ETA: 46s -  - ETA: 44s - loss: 0.3275 - acc:  - ETA: 43s - loss - ETA: 38s - loss:  - ETA: 37s -  - ETA: 28s - loss: 0.3315 - acc:  - ETA: 28s - loss: 0.3315 - a - ETA: 27s - loss: 0.3312 - ETA: 26s - loss: 0.3319 - acc: 0.88 - ETA: 26s - loss: 0.3320 - ETA: 22s - loss: 0.33 - ETA: 20s - loss: 0.3332 - - ETA: 19s - loss:  - ETA: 17s - loss: 0.3331 - acc: 0.87 - ETA: 17s - loss: 0. - ETA: 16s - loss:  - ETA: 10s - loss: 0.3356 - a - ETA: 10s - loss: 0.3354 -  - ETA: 8s - loss: 0.3372 -  - ETA: 7s - loss: 0.3381 - acc - ETA: 5s - loss: 0.3380 - acc: 0.8 - ETA: 5s - loss: 0.3384  - ETA: 3s - loss: 0.3386 - acc: 0.87 - ETA: 2s - loss: 0.3390 - acc: 0 - ETA: 2s - loss: 0.3396 - acc:\n",
      "Epoch 2/5\n",
      "523/523 [==============================] - 92s 176ms/step - loss: 0.3363 - acc: 0.8800: 12:36 -  - ETA: 4:37 - loss: 0.3364 - a - ETA: 3:51 - loss: 0.3423 - acc: 0 - ETA: 3:34 - loss: 0.3405 - acc: 0.87 - ETA: 3:29 - loss: - ETA: 2:31 - loss: - ETA: 2:05 - loss: 0.3444 - acc: 0 - ETA: 2:01 - loss: 0.3428 - acc: - ETA: 1:56 - loss: 0.3 - ETA: 1:43 - loss: 0.3360 - acc: 0 - ETA: 1:39 - loss: 0 - ETA: 1:31 - loss: 0.3410 - ac - ETA: 1:27 - loss: - ETA: 1:18 - loss: 0.3403 - acc:  - ETA: 1:15 - loss: 0.3414 - acc: 0.87 - ETA: 1:14 - loss: 0.3408 - acc:  - ETA: 1:11 - loss: 0.3406 - ETA: 1:07 - loss: 0.3419 - acc: 0.8 - ETA: 1:05 - loss: 0.3399 - acc: 0 - ETA: 1:04 - loss: 0.3388 - - ETA: 1:00 - loss: 0.3407 - ac - ETA: 59s - loss - ETA: 53s - loss: 0.3426 - acc:  - ETA: 53s - loss: 0.3423 - acc:  - ETA: 51s - loss: 0.3421 - - ETA: 50s - loss: 0.3411 - acc - E - ETA: 29s - loss: 0. - ETA:  - ETA: 24s - loss: 0.3395 - ETA: 18s - loss: 0.33 - ETA: 16s - loss: 0.3377 - - ETA: 15s - loss: 0.3379 - acc - ETA:  - ETA: 3s - loss: 0.3371 - acc: 0.879 - ETA: 3s - loss: 0.3371 - acc:  - ETA: 2s - loss: 0.3369 - acc:\n",
      "Epoch 3/5\n",
      "523/523 [==============================] - 91s 175ms/step - loss: 0.3410 - acc: 0.8785TA: 43:23 - loss: 0.3682 - acc: 0. - ETA: 22:05 - loss: 0.3532 - ETA: 10:53 - lo - ETA: 4:44 - loss: 0.3112 - acc: 0.88 - ETA: 4:31 - loss: 0.3127 -  - ETA: 3:39 - loss: 0.3117 - - ETA: 2:58 - loss: 0. - ETA: 1:44 - loss: 0.3437 - acc: 0.8 - ETA: 1:42 - loss: 0.3459 -  - ETA: 1:36 - loss: 0.3472 - acc: 0. - ETA: 1:34 - loss: 0.3492 - acc: 0. - ETA: 1:31 - loss: 0.3508 - acc: 0. - ETA: 1:30 - loss: 0.3517 - acc: 0.8 - ETA: 1:29 - loss: 0.3509 - acc: - ETA: 1:25 - loss: 0.3512 - acc: 0 - ETA: 1:24 - loss: 0.3514 - acc: 0.8 - ETA: 1:22 - loss: 0.35 - ETA: 1:16 - loss: 0.3541 - acc - ETA: 1:13 - - ETA: 1:03 - lo - ETA: 57s - loss: 0.3503 - a - ETA: 56s - loss: 0. - ETA: 54s - loss: 0.3489 - - ETA: 51s - loss: 0.3477 - a - ETA: 48s - loss: 0.3472 - a - ETA: 47s  - ETA: 44s - loss: 0.34 - ETA: 42s - loss: 0.34 - ETA - ETA: 35s - loss: 0.3398 - acc:  - ETA: 34s - loss: 0.3397 - acc:  - ETA: 33s - loss: 0.3395 - ETA: 31s - loss: 0.3412 - acc - ETA: 31s - loss:  - ETA: 28s - loss: 0.3411 - acc:  - ETA: 28s - loss: 0. - ETA: 21s - loss:  - ETA: 18s - loss: 0.3400 - a - ETA: 17 - - ETA: 10s - loss: 0.3387 - ac - ETA: 9s - loss: 0.3391 - acc: 0.8 - ETA: 9s - loss: 0.339 - ETA: 6s - loss: 0.3397 - acc: - ETA: 5s - loss: 0.3403 - acc: - ETA: 3s - loss: 0.3409 - acc: 0. - ETA: 3s - loss: 0.3410 - ac - ETA: 0s - loss: 0.3409 - acc: 0.87\n",
      "Epoch 4/5\n",
      "523/523 [==============================] - 91s 173ms/step - loss: 0.3274 - acc: 0.8834: 7:41 - loss: 0.3564 - acc: 0.87 - ETA: 7:04 - loss: 0.3492 - acc: 0. - ETA: 6:04  - ETA: 1:37 - loss: 0.3255 - acc: 0. - ETA: 1:35 - loss: 0.3276 - acc: 0.8 - ETA: 1:33 - loss: 0.3297 - acc: 0.879 - ETA: 1:33 - loss: 0.3292 - acc: - ETA: 1:29 - loss: 0.3289 - acc: 0.879 - ETA: 1:29 - loss: 0.3275 - ETA: 1:23 - loss: 0.3290 - ac - ETA: 1:19 - loss: 0.3271 - acc: 0.8 - ETA: 1:18 - lo - ETA: 1:08 - loss: - ETA: 54s - loss: 0.3279 - acc:  - ETA: 53s - loss: 0. - ETA: 50s - loss: 0.3267 - acc:  - ETA: 49s - loss: 0. - ETA: 47s - loss: 0.3247 - acc - ETA: 46s - loss: 0.3253 - acc - ETA: 45s  - ETA: 31s - loss: 0.3228 - a - ETA: 30s - loss: 0.3238 - acc:  - ETA: 29s - loss: 0.3248 - acc: 0. - ETA: 29s  - ETA: 26s  - ETA: 22s - loss: 0.3253 - - ETA: 21s - loss: 0.3259 - - ETA: 20s - loss - ETA: 14s - lo - ETA: 11s - loss: 0.32 - ETA: 9s - loss: 0.325 - ETA: 6s - loss: 0.3266 - acc: 0.88 - ETA: 5s - loss: 0.3268 - acc: 0.88 - ETA: 5s - loss: 0.3268 - acc: 0 - ETA: 4s - loss: 0.3267 - ac - ETA: 2s - loss: 0.3269 - acc\n",
      "Epoch 5/5\n",
      "523/523 [==============================] - 90s 173ms/step - loss: 0.3277 - acc: 0.8821: 22:3 - ETA: 5:19 - loss: 0.3412 - acc - ETA: 4:23 - loss:  - ETA: 3:00 - loss: 0.3402 - acc: 0.8 - ETA: 2:54 - loss: 0.3374 - ac - ETA: 2:40 - loss: 0.3 - ETA: 2:14 - loss: 0.3291 - acc: 0 - ETA: 2:10 - loss: 0.3270 - acc: 0. - ETA: 2:05 - loss: 0.3252 - acc: 0. - ETA: 2:02 - loss: 0.3234 - ac - ETA: 1:53 - loss: 0.3237 - acc: 0 - ETA: 1:50 - l - ETA: 1:34 - loss: 0.3247 - acc: 0.88 - ETA: 1:33 - loss: 0.3239  - ETA: 1:24 - loss: 0.3219 - acc: 0.8 - ETA: 1:23 - loss: 0.3224 - acc: - ETA: 1:20 - loss: 0.3216 - ETA: 1:15 - loss: 0.3215 - acc: 0.88 - ETA: 1:14 - loss: 0.3222 - acc: 0.88 - ETA: 1:13 - loss: 0.3217 - acc: 0 - ETA: 1:12 - loss: 0.3203 - acc: 0 - ETA: 1:11 - loss: 0.3204 - acc: 0 - ETA: 1:09 - loss: 0.3221 - acc: 0.8 - ETA: 1:08 - loss: 0.3212 - acc: 0.8 - ETA: 1:05 - loss: 0.3214 - acc: 0. - ETA: 1:04 - loss: 0.3213 - ac - ETA: 1:02 - loss: 0.3209 - acc: 0. - ETA: 1:01 - loss: 0.3202 - acc: 0 - ETA: 1:00 - loss: 0.3211 - acc: 0 - ETA: 58s - lo - ETA: 55s - loss - ETA: 51s - loss: 0.32 - ETA: 49s - loss: 0.32 - ETA: 47s - lo - E - ETA - ETA: 29s - loss: 0.3216 - acc - ETA: 28s - loss:  - E - ETA:  - ETA: 19s - loss - ETA: 17s - loss: 0.3261 - ETA: 16 - E - ETA: 9s - loss: 0.3285 - acc: 0.88 - ETA: 9s - loss: 0. - ETA: 6s - loss: 0.3285 - a - ETA: 4s - loss: 0.3289 - acc: 0.8 - ETA: 3s - loss: 0.3287 - acc: 0.88 - ETA: 2s - loss: 0.3284 - acc: 0 - ETA: 1s - loss: 0.3287 - acc: 0.\n",
      "[End of Training]\n"
     ]
    }
   ],
   "source": [
    "import warnings; \n",
    "warnings.simplefilter('ignore')\n",
    "trainer.start(epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:00:52.015870Z",
     "start_time": "2018-06-05T07:00:51.995534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./models/metal_predict.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./models/metal_predict.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# later...\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('type.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"type.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_args = {'sequences': seqs,\n",
    "              'labels': target,\n",
    "              'translator': vocab_dic_fofe}\n",
    "common_args = {'batch_size': 1,\n",
    "               'input_shape': (800,),\n",
    "               'label_shape': (13, ),\n",
    "               'shuffle': False}\n",
    "train_gen = modules_type.FOFEGenerator(**train_args, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metal_predictions = []\n",
    "Y = []\n",
    "for i in range(len(train_gen)):\n",
    "    x,y = train_gen[i]\n",
    "    metal_predictions.append(model.predict(x))\n",
    "    Y.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_label_dict = {v: k for k, v in label_dict.items()}\n",
    "l1 = []\n",
    "l2 = []\n",
    "for i,j in enumerate(Y):\n",
    "    max_i = max(j[0])\n",
    "    x = [a for a, b in enumerate(Y[i][0]) if b == max_i]\n",
    "    l2.append(inv_label_dict[x[0]])\n",
    "    \n",
    "for i,j in enumerate(metal_predictions):\n",
    "    max_i = max(j[0])\n",
    "    x = [a for a, b in enumerate(metal_predictions[i][0]) if b == max_i]\n",
    "    l1.append(inv_label_dict[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(l1)):\n",
    "    if l1[i] != l2[i]:\n",
    "        c+=1\n",
    "print ((len(l1)-c) / len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['metalPrediction'] = np.array(l1, dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['metalPrediction'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_json('Metal_all_20180601_predicted.parquet', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_json('Metal_all_20180601_predicted.parquet', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (l1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (l2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove seqs containing 'U' and 'X'\n",
    "\n",
    "duplicate_dict = {}\n",
    "rows_to_delete = []\n",
    "for i in range(seqs.shape[0]):\n",
    "    if 'X' in seqs[i] \\\n",
    "    or 'U' in seqs[i] \\\n",
    "    or '3CO' in target[i]\\\n",
    "    or '3NI' in target[i] \\\n",
    "    or 'FE2'in target[i] \\\n",
    "    or 'CU1'in target[i]\\\n",
    "    or 'MN3' in target[i] \\\n",
    "    or np.isnan(cluster_numbers[i]):\n",
    "        rows_to_delete.append(i)\n",
    "        print (i, end=',')\n",
    "    elif seqs[i] not in duplicate_dict.keys():\n",
    "        duplicate_dict[seqs[i]] = target[i]\n",
    "    else:\n",
    "        if target[i] != duplicate_dict[seqs[i]]:\n",
    "            rows_to_delete.append(i)\n",
    "            print (i, end=',')\n",
    "    \n",
    "# df = df.drop(df.index[rows_to_delete])\n",
    "# df.to_parquet('Metal_all_20180601.parquet')\n",
    "seqs = np.delete(seqs, rows_to_delete, 0)\n",
    "target = np.delete(target, rows_to_delete)\n",
    "cluster_numbers = np.delete(cluster_numbers, rows_to_delete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
